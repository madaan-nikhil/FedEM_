{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sweep Transfer Attack\n",
    "\n",
    "9.29.21\n",
    "\n",
    "#### Summary:\n",
    "- Made each client (7 options) adversarial and perform transfer attacks throughout the system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/FedEM\n"
     ]
    }
   ],
   "source": [
    "cd /home/ubuntu/FedEM/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Relevant Libraries\n",
    "Take it from the run_experiment.py folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "# Import General Libraries\n",
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "import copy\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Import FedEM based Libraries\n",
    "from utils.utils import *\n",
    "from utils.constants import *\n",
    "from utils.args import *\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from run_experiment import *\n",
    "from models import *\n",
    "\n",
    "# Import Transfer Attack\n",
    "from transfer_attacks.Personalized_NN import *\n",
    "from transfer_attacks.Params import *\n",
    "from transfer_attacks.Transferer import *\n",
    "from transfer_attacks.Args import *\n",
    "from transfer_attacks.TA_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Aggregator Pre-requisite\n",
    "- Clients, Test Clients, Ensemble_Learner\n",
    "- Follow through the code in run_experiment.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Clients initialization..\n",
      "===> Building data iterators..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [00:00<00:00, 262.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Initializing clients..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [00:12<00:00,  6.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Test Clients initialization..\n",
      "===> Building data iterators..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Initializing clients..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++\n",
      "Global..\n",
      "Train Loss: 2.297 | Train Acc: 10.806% |Test Loss: 2.299 | Test Acc: 10.238% |\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "################################################################################\n"
     ]
    }
   ],
   "source": [
    "args_ = Args()\n",
    "args_.experiment = \"cifar10\"\n",
    "args_.method = \"local\"\n",
    "args_.decentralized = False\n",
    "args_.sampling_rate = 1.0\n",
    "args_.input_dimension = None\n",
    "args_.output_dimension = None\n",
    "args_.n_learners= 1\n",
    "args_.n_rounds = 10\n",
    "args_.bz = 128\n",
    "args_.local_steps = 1\n",
    "args_.lr_lambda = 0\n",
    "args_.lr =0.03\n",
    "args_.lr_scheduler = 'multi_step'\n",
    "args_.log_freq = 10\n",
    "args_.device = 'cuda'\n",
    "args_.optimizer = 'sgd'\n",
    "args_.mu = 0\n",
    "args_.communication_probability = 0.1\n",
    "args_.q = 1\n",
    "args_.locally_tune_clients = False\n",
    "args_.seed = 1234\n",
    "args_.verbose = 1\n",
    "args_.save_path = 'weights/cifar10/local/'\n",
    "args_.validation = False\n",
    "args_.tune_steps = 0\n",
    "aggregator, clients = dummy_aggregator(args_, num_user=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import weights for aggregator\n",
    "# aggregator.load_state(args_.save_path)\n",
    "\n",
    "# # This is where the models are stored -- one for each mixture --> learner.model for nn\n",
    "# hypotheses = aggregator.global_learners_ensemble.learners\n",
    "\n",
    "# # obtain the state dict for each of the weights \n",
    "# weights_h = []\n",
    "\n",
    "# for h in hypotheses:\n",
    "#     weights_h += [h.model.state_dict()]\n",
    "    \n",
    "# # Determine here the different weights of models we desire to compare\n",
    "# model_weights = []\n",
    "\n",
    "# model_weights += [(1,0,0),(0,1,0),(0,0,1)] #single mixture\n",
    "# model_weights += [(0.5,0.5,0),(0.5,0,0.5),(0,0.5,0.5)] # half of 2 mixtures of 3\n",
    "# model_weights += [(1/3,1/3,1/3)] # Equally balanced from 3 mixtures\n",
    "\n",
    "# # Generate the weights to test on as linear combinations of the model_weights\n",
    "# models_test = []\n",
    "\n",
    "# for (w0,w1,w2) in model_weights:\n",
    "#     # first make the model with empty weights\n",
    "#     new_model = copy.deepcopy(hypotheses[0].model)\n",
    "#     new_model.eval()\n",
    "#     new_weight_dict = copy.deepcopy(weights_h[0])\n",
    "#     for key in weights_h[0]:\n",
    "#         new_weight_dict[key] = w0*weights_h[0][key] + w1*weights_h[1][key] + w2*weights_h[2][key]\n",
    "#     new_model.load_state_dict(new_weight_dict)\n",
    "#     models_test += [new_model]\n",
    "\n",
    "num_models = 40\n",
    "\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.2f}\".format(x)})\n",
    "\n",
    "setting = 'local'\n",
    "\n",
    "if setting == 'local':\n",
    "\n",
    "#     args_.save_path = 'weights/final/femnist/fig1_take3/local_benign/'\n",
    "#     args_.save_path ='weights/final/femnist/fig1_take3/local_adv/'\n",
    "    aggregator.load_state(args_.save_path)\n",
    "    \n",
    "    model_weights = []\n",
    "#     weights = np.load(\"weights/final/femnist/fig1_take3/local_benign/train_client_weights.npy\")\n",
    "    weights = np.load(args_.save_path + 'train_client_weights.npy')\n",
    "    \n",
    "    for i in range(num_models):\n",
    "        model_weights += [weights[i]]\n",
    "\n",
    "    # Generate the weights to test on as linear combinations of the model_weights\n",
    "    models_test = []\n",
    "\n",
    "    for i in range(num_models):\n",
    "        new_model = copy.deepcopy(aggregator.clients[i].learners_ensemble.learners[0].model)\n",
    "        new_model.eval()\n",
    "        models_test += [new_model]\n",
    "\n",
    "elif setting == 'FedAvg':\n",
    "    \n",
    "#     args_.save_path = 'weights/final/femnist/fig1_take3/fedavg_benign/'\n",
    "#     args_.save_path = 'weights/final/femnist/fig1_take3/FedAvg_adv/'\n",
    "    aggregator.load_state(args_.save_path)\n",
    "    \n",
    "    # This is where the models are stored -- one for each mixture --> learner.model for nn\n",
    "    hypotheses = aggregator.global_learners_ensemble.learners\n",
    "\n",
    "    # obtain the state dict for each of the weights \n",
    "    weights_h = []\n",
    "\n",
    "    for h in hypotheses:\n",
    "        weights_h += [h.model.state_dict()]\n",
    "\n",
    "#     weights = np.load(\"weights/final/femnist/fig1_take3/fedavg_benign/train_client_weights.npy\")\n",
    "    weights = np.load(args_.save_path + 'train_client_weights.npy')\n",
    "    \n",
    "    # Set model weights\n",
    "    model_weights = []\n",
    "\n",
    "    for i in range(num_models):\n",
    "        model_weights += [weights[i]]\n",
    "\n",
    "    # Generate the weights to test on as linear combinations of the model_weights\n",
    "    models_test = []\n",
    "\n",
    "    for (w0) in model_weights:\n",
    "        # first make the model with empty weights\n",
    "        new_model = copy.deepcopy(hypotheses[0].model)\n",
    "        new_model.eval()\n",
    "        new_weight_dict = copy.deepcopy(weights_h[0])\n",
    "        for key in weights_h[0]:\n",
    "            new_weight_dict[key] = w0[0]*weights_h[0][key] \n",
    "        new_model.load_state_dict(new_weight_dict)\n",
    "        models_test += [new_model]\n",
    "\n",
    "elif setting == 'FedEM':\n",
    "    \n",
    "#     args_.save_path = 'weights/cifar/21_12_30_feddef_n40_linf0_5_G0_0/'\n",
    "#     args_.save_path = 'weights/final/femnist/fig1_take3/fedem_adv/'\n",
    "#     args_.save_path = 'weights/final/femnist/figperturb/fedem_avg_p0_1/'\n",
    "    aggregator.load_state(args_.save_path)\n",
    "    \n",
    "    # This is where the models are stored -- one for each mixture --> learner.model for nn\n",
    "    hypotheses = aggregator.global_learners_ensemble.learners\n",
    "\n",
    "    # obtain the state dict for each of the weights \n",
    "    weights_h = []\n",
    "\n",
    "    for h in hypotheses:\n",
    "        weights_h += [h.model.state_dict()]\n",
    "\n",
    "#     weights = np.load(\"weights/cifar/21_12_30_feddef_n40_linf0_5_G0_0/train_client_weights.npy\")\n",
    "    weights = np.load(args_.save_path+\"train_client_weights.npy\")\n",
    "#     weights = np.load(\"weights/final/femnist/fig1_take3/fedem_adv/train_client_weights.npy\")\n",
    "#     weights = np.load(\"weights/final/femnist/figperturb/fedem_avg_p0_1/train_client_weights.npy\")\n",
    "\n",
    "    # Set model weights\n",
    "    model_weights = []\n",
    "\n",
    "    for i in range(num_models):\n",
    "        model_weights += [weights[i]]\n",
    "\n",
    "\n",
    "    # Generate the weights to test on as linear combinations of the model_weights\n",
    "    models_test = []\n",
    "\n",
    "    for (w0,w1,w2) in model_weights:\n",
    "        # first make the model with empty weights\n",
    "        new_model = copy.deepcopy(hypotheses[0].model)\n",
    "        new_model.eval()\n",
    "        new_weight_dict = copy.deepcopy(weights_h[0])\n",
    "        for key in weights_h[0]:\n",
    "            new_weight_dict[key] = w0*weights_h[0][key] + w1*weights_h[1][key] + w2*weights_h[2][key]\n",
    "        new_model.load_state_dict(new_weight_dict)\n",
    "        models_test += [new_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<learners.learner.Learner at 0x7f4c8877ca90>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregator.global_learners_ensemble.learners"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine Validation Data across all clients as test\n",
    "data_x = []\n",
    "data_y = []\n",
    "\n",
    "for i in range(len(clients)):\n",
    "    daniloader = clients[i].val_iterator\n",
    "    for (x,y,idx) in daniloader.dataset:\n",
    "        data_x.append(x)\n",
    "        data_y.append(y)\n",
    "\n",
    "data_x = torch.stack(data_x)\n",
    "data_y = torch.stack(data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataloader from validation dataset that allows for diverse batch size\n",
    "dataloader = Custom_Dataloader(data_x, data_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Up Transfer Attack Scenario\n",
    "- Set up order of which attacks will take place -- keep the same transferer, but simply swap out the weights of the adversary and flush out the existing data points analysis was done on\n",
    "- Make dictionaries beforehand recording all of the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Up Dictionaries -- list holds the adversary idx\n",
    "logs_adv = []\n",
    "\n",
    "for i in range(len(model_weights)):\n",
    "    adv_dict = {}\n",
    "    adv_dict['orig_acc_transfers'] = None\n",
    "    adv_dict['orig_similarities'] = None\n",
    "    adv_dict['adv_acc_transfers'] = None\n",
    "    adv_dict['adv_similarities'] = None\n",
    "    adv_dict['orig_target_hit'] = None\n",
    "    adv_dict['adv_target_hit'] = None\n",
    "    adv_dict['metric_variance'] = None\n",
    "    adv_dict['metric_alignment'] = None\n",
    "    adv_dict['metric_ingrad'] = None\n",
    "    logs_adv += [adv_dict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id 0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "cannot reshape tensor of 0 elements into shape [0, -1] because the unspecified dimension size -1 can be any value and is ambiguous",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5799/2017456698.py\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mt1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_xadv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0matk_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"ifsgm\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mt1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_to_victims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvictim_idxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mt1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_empirical_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_flag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;31m# t1.check_empirical_metrics()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/FedEM/transfer_attacks/Transferer.py\u001b[0m in \u001b[0;36mcheck_empirical_metrics\u001b[0;34m(self, orig_flag, batch_size)\u001b[0m\n\u001b[1;32m    199\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetric_ingrad_adv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetric_alignment\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalcNN_alignment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvictims\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetric_ingrad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalcNN_ingrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvictims\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/FedEM/transfer_attacks/Attack_Metrics.py\u001b[0m in \u001b[0;36mcalcNN_alignment\u001b[0;34m(network1, network2, data_x, data_y)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;31m# Obtain gradient with respect to each input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mx_adv1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0mh_adv1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_adv1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m     \u001b[0mcost1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_adv1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/FedEM/transfer_attacks/Personalized_NN.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrained_network\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torchvision/models/mobilenet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torchvision/models/mobilenet.py\u001b[0m in \u001b[0;36m_forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0;31m# Cannot use \"squeeze\" as batch-size can be 1 => must use reshape with x.shape[0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madaptive_avg_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cannot reshape tensor of 0 elements into shape [0, -1] because the unspecified dimension size -1 can be any value and is ambiguous"
     ]
    }
   ],
   "source": [
    "# Make transferer and Assign model index\n",
    "victim_idxs = [0,1,2,3,4,5,6]\n",
    "\n",
    "t1 = Transferer(models_list=models_test, dataloader=dataloader)\n",
    "\n",
    "for adv_idx in victim_idxs:\n",
    "    print(\"id\", adv_idx)\n",
    "    # Perform Attack\n",
    "    \n",
    "    t1.generate_victims(victim_idxs)\n",
    "    t1.generate_advNN(adv_idx)\n",
    "    t1.generate_xadv(atk_type = \"ifsgm\")\n",
    "    t1.send_to_victims(victim_idxs)\n",
    "    # t1.check_empirical_metrics(orig_flag = True)\n",
    "    t1.check_empirical_metrics()\n",
    "    \n",
    "    # Log Performance\n",
    "    logs_adv[adv_idx]['orig_acc_transfers'] = t1.orig_acc_transfers\n",
    "    logs_adv[adv_idx]['orig_similarities'] = t1.orig_similarities\n",
    "    logs_adv[adv_idx]['adv_acc_transfers'] = t1.adv_acc_transfers\n",
    "    logs_adv[adv_idx]['adv_similarities'] = t1.adv_similarities\n",
    "    logs_adv[adv_idx]['orig_target_hit'] = t1.orig_target_hit\n",
    "    logs_adv[adv_idx]['adv_target_hit'] = t1.adv_target_hit\n",
    "    \n",
    "    logs_adv[adv_idx]['metric_variance'] = t1.metric_variance\n",
    "    logs_adv[adv_idx]['metric_alignment'] = t1.metric_alignment\n",
    "    logs_adv[adv_idx]['metric_ingrad'] = t1.metric_ingrad\n",
    "    logs_adv[adv_idx]['metric_loss'] = t1.metric_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torchvision.models.mobilenet.MobileNetV2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(t1.advNN.trained_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print and Record Results\n",
    "- Organize the results into a matrix and print them into an excel sheet\n",
    "- Following Categories (sim_benign, sim_adv, target_adv,grad_alignment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['orig_similarities','adv_similarities','adv_target_hit','metric_alignment']\n",
    "\n",
    "sim_benign = np.zeros([len(victim_idxs),len(victim_idxs)]) \n",
    "sim_adv = np.zeros([len(victim_idxs),len(victim_idxs)]) \n",
    "target_adv = np.zeros([len(victim_idxs),len(victim_idxs)]) \n",
    "grad_align = np.zeros([len(victim_idxs),len(victim_idxs)]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for adv_idx in victim_idxs:\n",
    "    for victim in victim_idxs:\n",
    "        sim_benign[adv_idx,victim] = logs_adv[adv_idx][metrics[0]][victim].data.tolist()\n",
    "        sim_adv[adv_idx,victim] = logs_adv[adv_idx][metrics[1]][victim].data.tolist()\n",
    "        target_adv[adv_idx,victim] = logs_adv[adv_idx][metrics[2]][victim].data.tolist()\n",
    "        grad_align[adv_idx,victim] = logs_adv[adv_idx][metrics[3]][victim].data.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to Excel file\n",
    "\n",
    "## convert your array into a dataframe\n",
    "sim_benign_df = pd.DataFrame(sim_benign)\n",
    "sim_adv_df = pd.DataFrame(sim_adv)\n",
    "target_adv_df = pd.DataFrame(target_adv)\n",
    "grad_align_df = pd.DataFrame(grad_align)\n",
    "\n",
    "## save to xlsx file\n",
    "\n",
    "#filepath = 'my_excel_file.xlsx'\n",
    "\n",
    "# df.to_excel(filepath, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6\n",
       "0  1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       "1  1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       "2  1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       "3  1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       "4  1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       "5  1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       "6  1.0  1.0  1.0  1.0  1.0  1.0  1.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_benign_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6\n",
       "0  1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       "1  1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       "2  1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       "3  1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       "4  1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       "5  1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       "6  1.0  1.0  1.0  1.0  1.0  1.0  1.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_adv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.792411</td>\n",
       "      <td>0.792411</td>\n",
       "      <td>0.792411</td>\n",
       "      <td>0.792411</td>\n",
       "      <td>0.792411</td>\n",
       "      <td>0.792411</td>\n",
       "      <td>0.792411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.744444</td>\n",
       "      <td>0.744444</td>\n",
       "      <td>0.744444</td>\n",
       "      <td>0.744444</td>\n",
       "      <td>0.744444</td>\n",
       "      <td>0.744444</td>\n",
       "      <td>0.744444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.784922</td>\n",
       "      <td>0.784922</td>\n",
       "      <td>0.784922</td>\n",
       "      <td>0.784922</td>\n",
       "      <td>0.784922</td>\n",
       "      <td>0.784922</td>\n",
       "      <td>0.784922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.771242</td>\n",
       "      <td>0.771242</td>\n",
       "      <td>0.771242</td>\n",
       "      <td>0.771242</td>\n",
       "      <td>0.771242</td>\n",
       "      <td>0.771242</td>\n",
       "      <td>0.771242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.758465</td>\n",
       "      <td>0.758465</td>\n",
       "      <td>0.758465</td>\n",
       "      <td>0.758465</td>\n",
       "      <td>0.758465</td>\n",
       "      <td>0.758465</td>\n",
       "      <td>0.758465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.743304</td>\n",
       "      <td>0.743304</td>\n",
       "      <td>0.743304</td>\n",
       "      <td>0.743304</td>\n",
       "      <td>0.743304</td>\n",
       "      <td>0.743304</td>\n",
       "      <td>0.743304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.735294</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>0.735294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6\n",
       "0  0.792411  0.792411  0.792411  0.792411  0.792411  0.792411  0.792411\n",
       "1  0.744444  0.744444  0.744444  0.744444  0.744444  0.744444  0.744444\n",
       "2  0.784922  0.784922  0.784922  0.784922  0.784922  0.784922  0.784922\n",
       "3  0.771242  0.771242  0.771242  0.771242  0.771242  0.771242  0.771242\n",
       "4  0.758465  0.758465  0.758465  0.758465  0.758465  0.758465  0.758465\n",
       "5  0.743304  0.743304  0.743304  0.743304  0.743304  0.743304  0.743304\n",
       "6  0.735294  0.735294  0.735294  0.735294  0.735294  0.735294  0.735294"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_adv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "5  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "6  0.0  0.0  0.0  0.0  0.0  0.0  0.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_align_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad_allign 0.0 0.0\n"
     ]
    }
   ],
   "source": [
    "def avg_nondiag1(array2d):\n",
    "    d1 = array2d.shape[0]\n",
    "    d2 = array2d.shape[1]\n",
    "    \n",
    "    counter = 0\n",
    "    val = 0\n",
    "\n",
    "    v = []\n",
    "    \n",
    "    for i1 in range(d1):\n",
    "        for i2 in range(d2):\n",
    "            if i1 != i2:\n",
    "                counter+=1\n",
    "                v.append(array2d[i1,i2])\n",
    "    \n",
    "    return np.array(v)\n",
    "\n",
    "z = avg_nondiag1(grad_align_df.to_numpy())\n",
    "print(f'grad_allign {z.mean()} {z.std()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.1332879066467285 +- 3.925236701965332\n"
     ]
    }
   ],
   "source": [
    "z = np.array([logs_adv[id]['metric_loss'].detach().cpu().numpy() for id in (victim_idxs)]).var(axis=0)\n",
    "\n",
    "print(f'{np.mean(z)} +- {np.std(z)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([-14.6847,  -9.0861, -12.1590, -13.0355,  -5.5307, -13.0642, -11.6901,\n",
       "          -9.6894,  -9.6512,  -9.2321,  -9.7385, -10.8485,  -6.6340,  -8.3732,\n",
       "          -5.5682, -11.2091, -10.6277,  -9.3931, -14.4224,  -9.3846,  -8.0889,\n",
       "          -6.4126, -11.4183,  -8.0432, -10.9291,  -9.7856, -11.1508,  -4.7621,\n",
       "          -7.2178,  -8.8826, -10.5308,  -8.7114, -11.6912,  -5.5029,  -7.8941,\n",
       "         -12.3183, -10.3462,  -8.0230, -10.1024,  -8.0224,  -6.9404,  -8.4764,\n",
       "         -13.2745,  -8.2184,  -6.2232, -12.3560, -11.2209, -15.3736,  -7.3440,\n",
       "         -10.0745, -11.9058, -12.4361,  -9.1927,  -7.6689, -10.1026,  -7.5964,\n",
       "          -4.3444, -10.6786,  -9.0685,  -6.1704, -14.1429,  -8.9850,  -8.8894,\n",
       "         -11.4450,  -6.7559,  -5.4971,  -6.0202,  -8.4138,  -9.4734,  -6.2315,\n",
       "          -9.0226,  -9.0838,  -9.6282, -11.1408, -15.5767,  -8.0454, -12.8567,\n",
       "         -12.7224,  -9.2411,  -6.4083,  -7.7427,  -9.5992,  -6.8571,  -9.2849,\n",
       "         -13.4315,  -7.0483, -13.6009, -10.2901,  -7.9015,  -9.3879, -10.2759,\n",
       "          -9.7442,  -6.6625,  -5.9729, -10.1053,  -5.9142,  -7.5771,  -9.7805,\n",
       "          -8.8147, -10.3492,  -8.4855,  -4.8895, -12.4895, -10.3556,  -7.8970,\n",
       "          -8.0382, -11.3448, -13.2898,  -8.4233, -10.4313,  -5.6903, -11.2118,\n",
       "         -12.5297, -11.2886, -14.5809,  -8.4470,  -6.2488,  -8.5734,  -9.9684,\n",
       "         -17.3562,  -8.0152,  -9.9092, -11.0087,  -9.3904,  -8.0209,  -8.5703,\n",
       "          -7.2883,  -6.2745,  -9.8389, -11.9276,  -7.4578,  -6.4622,  -8.4845,\n",
       "          -7.2799,  -7.5715, -13.0965,  -6.3538,  -7.3174,  -6.4638,  -4.4506,\n",
       "          -6.8052, -10.7327, -12.2034,  -6.4956,  -8.9092, -12.1766,  -8.6324,\n",
       "         -10.7358, -10.1379,  -9.8095,  -8.8737,  -9.2660,  -6.9849,  -9.1743,\n",
       "         -11.6991,  -7.9925, -12.5411,  -7.2620,  -9.8585,  -8.0626,  -6.9688,\n",
       "          -8.2833,  -8.0714,  -9.6664,  -7.0164,  -9.3267, -11.7726, -11.6810,\n",
       "          -9.0411,  -7.7759, -18.7036, -10.5280, -10.2716,  -9.5048, -10.4682,\n",
       "          -9.1794,  -5.2644,  -9.2865, -12.8691,  -5.2653, -10.7075,  -8.7423,\n",
       "         -12.1424,  -4.5720,  -8.7487, -11.7045,  -6.9706,  -4.7365, -12.2366,\n",
       "          -4.3123,  -8.1441,  -8.2157, -14.1446,  -9.4240,  -8.5978,  -6.8579,\n",
       "         -16.0877,  -5.7762, -10.2855, -10.5475,  -9.1738,  -9.6606,  -6.8522,\n",
       "         -12.6672,  -8.9341,  -5.4324,  -7.9743,  -7.0987,  -7.8487,  -7.2968,\n",
       "          -8.9537,  -7.8836, -10.1102,  -9.4470,  -6.7718,  -6.0724, -11.2887,\n",
       "          -9.1661,  -9.3709,  -6.4972,  -9.5701,  -9.4744, -14.9272,  -7.8930,\n",
       "         -11.7004,  -8.1030,  -9.6438, -11.2551,  -7.6661, -10.6227,  -6.0089,\n",
       "         -10.3732,  -5.9334,  -7.5486,  -8.0243,  -7.1378, -11.3003,  -9.5541,\n",
       "         -12.0555,  -6.2448, -11.6140,  -7.9909,  -8.8858, -10.5076,  -9.1495,\n",
       "         -12.3838,  -9.1659, -11.4744,  -5.8257,  -9.7874,  -6.2971, -10.4682,\n",
       "         -14.5756,  -4.9327,  -5.9792, -13.7579,  -9.5561, -13.0774,  -3.9441,\n",
       "          -8.3286,  -5.7838,  -6.5065,  -4.6814,  -9.2508,  -6.0662,  -8.6132,\n",
       "          -6.5029, -12.0626, -11.8020, -14.2916,  -8.9460, -11.2908, -11.0527,\n",
       "         -11.4979, -12.7418,  -8.0073, -11.2552, -13.7808, -10.9293,  -4.6206,\n",
       "          -8.3226,  -2.8250,  -5.1054,  -8.5514,  -8.6518, -10.8909,  -4.1833,\n",
       "         -11.3631, -12.6625, -11.4562,  -6.6145, -16.1454,  -6.8070, -13.5733,\n",
       "         -11.6449,  -7.2948,  -6.1852,  -7.1125, -10.1052, -10.9900, -10.0796,\n",
       "          -8.0754,  -7.9757, -11.5710,  -9.8775, -12.9283,  -7.5239,  -9.2519,\n",
       "          -7.5661,  -7.6105, -11.6221, -12.9757,  -9.7886, -10.3459, -13.7034,\n",
       "         -10.6355, -17.9787,  -7.3375, -15.6421,  -4.7201,  -5.6714,  -6.6944,\n",
       "         -12.1551,  -9.4853, -16.3536,  -9.0153,  -7.1959, -13.8230,  -8.0151,\n",
       "         -15.9662, -18.1578,  -5.1684,  -6.0543,  -5.9040,  -8.4232,  -9.6275,\n",
       "          -6.0565,  -6.7026, -11.1356,  -8.4375,  -8.7940, -11.1379,  -4.8773,\n",
       "          -6.2471, -10.6251, -12.5180,  -9.6738, -10.8034, -10.9898,  -8.9170,\n",
       "          -6.5516, -10.3397, -12.1380, -13.4365,  -8.2764, -15.8632,  -7.8936,\n",
       "         -10.5408,  -9.7007,  -6.9516,  -9.0939,  -6.2990,  -9.4938,  -5.6467,\n",
       "         -12.1269, -10.7979,  -8.2739, -10.6175,  -7.8275, -12.3667,  -5.8339,\n",
       "          -9.4986,  -8.7392, -12.0865,  -9.1626,  -8.6400,  -9.6805, -10.2976,\n",
       "         -10.3950, -12.8613,  -5.8490,  -8.5998, -12.7340,  -8.1063, -10.2742,\n",
       "          -8.7487,  -7.5072,  -5.1260, -10.9089,  -9.6977, -11.0400,  -8.0679,\n",
       "          -8.9089,  -8.8924, -11.1063, -10.0188, -13.7779,  -8.6150, -10.9664,\n",
       "          -5.5453,  -9.6588, -11.6314, -11.0485,  -5.5564,  -7.3954,  -8.7218,\n",
       "         -11.6922,  -9.5705, -10.3185,  -6.3426, -10.5553, -12.0894,  -8.2484,\n",
       "          -8.1683,  -6.1483,  -7.9720, -15.1137,  -6.9008,  -6.8283, -16.0579,\n",
       "          -6.6370,  -7.0767,  -7.4091, -10.2383,  -8.8756, -12.7005,  -8.5889,\n",
       "         -11.6906, -15.8842, -11.9043,  -8.7236, -10.2710,  -9.3668,  -9.1159,\n",
       "          -8.7977,  -5.2469, -10.8270,  -7.2952, -10.0312,  -9.7328, -11.2726,\n",
       "          -9.1681,  -5.9376, -12.6366, -12.7324, -13.3555,  -8.2706,  -9.7566,\n",
       "          -8.4019, -14.2651,  -7.9019,  -6.0850,  -8.0834, -10.8089,  -7.7103,\n",
       "         -14.4233, -11.9730, -12.8045,  -7.5026, -11.9183,  -5.2937,  -7.3534,\n",
       "         -13.9481,  -7.9794, -11.1513, -10.5807,  -2.3405,  -5.9367, -10.2179,\n",
       "         -12.1337, -10.2335,  -5.9306,  -8.7163,  -8.6692,  -7.5222,  -4.0259,\n",
       "         -10.9360,  -8.7275,  -7.1063,  -9.3503, -10.8093, -14.6584,  -9.1351,\n",
       "          -9.4841,  -7.6487,  -8.2590,  -7.2533, -10.3644,  -5.5499, -10.3390,\n",
       "          -5.6980,  -9.6623,  -8.9349, -11.6951, -10.3659, -13.7856, -11.6626,\n",
       "         -10.3898, -10.4387, -10.7857], device='cuda:0',\n",
       "        grad_fn=<NllLossBackward>),\n",
       " tensor([ -5.9054,  -5.5054,  -8.7927,  -7.2740,  -8.6410,  -6.4429,  -9.7322,\n",
       "          -6.9712,  -8.1259,  -5.6973,  -8.3659,  -7.7342, -10.0642,  -6.8764,\n",
       "         -11.3263,  -9.2778,  -7.8016, -10.7705,  -6.5437,  -9.5055, -10.1245,\n",
       "          -7.4324, -15.7734,  -7.1353, -12.7483,  -7.8808,  -5.7179,  -7.2981,\n",
       "         -10.8800, -12.3264,  -8.8874,  -6.7794,  -6.4356,  -8.3180,  -5.2851,\n",
       "          -9.7607,  -6.6601, -16.1140,  -7.1657,  -7.6035,  -8.4525,  -7.5412,\n",
       "         -10.7704, -11.1416, -11.3594,  -9.4615,  -9.0885,  -5.0172,  -9.4688,\n",
       "          -9.1429,  -7.4826, -10.6058, -16.2325,  -7.0625,  -9.4038,  -7.4669,\n",
       "          -8.6308,  -9.9426, -12.7436, -12.2005,  -5.2841,  -9.5638, -10.7272,\n",
       "         -13.9831, -11.8664,  -8.6050,  -7.6687, -10.5272, -10.9930,  -9.5342,\n",
       "          -5.5499, -12.5021,  -9.1632, -11.1091,  -8.0361, -11.1593, -11.3947,\n",
       "         -11.7550, -10.8251,  -6.8965, -10.2566,  -7.4415, -13.1489, -10.4572,\n",
       "          -9.4189,  -8.4600,  -8.9669,  -6.7733, -12.3505,  -9.0437, -12.8779,\n",
       "          -2.3405,  -4.3007,  -6.9042,  -3.4686,  -9.6782,  -5.6504,  -8.7082,\n",
       "         -11.6906,  -9.6950,  -7.3440,  -7.5583, -10.1263, -10.5188, -11.3136,\n",
       "         -13.7480, -14.7550, -10.5126, -11.7645,  -6.2070, -17.4287, -14.1429,\n",
       "          -6.2143,  -8.7124,  -8.7142,  -8.1885,  -8.6566, -13.4176,  -9.0305,\n",
       "          -6.3609,  -8.4542,  -7.0910, -11.2607,  -5.1411,  -6.6197, -10.8391,\n",
       "          -8.1269,  -8.1250, -11.9435, -11.9429,  -7.4002, -10.1656,  -8.0435,\n",
       "          -6.0089,  -7.3239,  -8.1562, -10.5840, -12.2156,  -9.5599, -14.2957,\n",
       "         -10.4169,  -9.2288, -10.1878, -11.0754, -11.7532, -11.1028, -12.5992,\n",
       "          -6.3456, -12.0092,  -8.9506,  -6.0689, -14.7735,  -9.4503, -13.2924,\n",
       "          -9.5220, -11.7740,  -9.4234,  -6.0341,  -7.7657, -13.6537, -10.5153,\n",
       "          -4.0249, -13.9070,  -7.5322, -13.6661, -10.5307,  -8.5631,  -7.4348,\n",
       "         -13.1877,  -9.8035, -14.4029,  -9.2644, -12.5415,  -4.9264,  -8.8075,\n",
       "         -15.3619,  -7.2022,  -8.8545,  -8.9266,  -3.4615, -15.1160, -14.5521,\n",
       "          -9.6818, -12.7276,  -4.3062, -12.0144,  -8.8752,  -9.7842,  -7.3165,\n",
       "          -8.9117,  -8.4582,  -9.8400,  -5.5443,  -6.3830,  -5.8959,  -8.4138,\n",
       "          -9.1330,  -9.5992,  -7.2979,  -7.4890,  -9.6320, -19.3424,  -9.7262,\n",
       "         -12.8668, -10.9780, -11.6637,  -6.5451, -12.2653,  -6.2082,  -5.0587,\n",
       "          -8.8316,  -6.9841,  -7.6195,  -5.7119,  -9.3521,  -8.2671,  -9.0784,\n",
       "          -8.5470, -13.0436,  -4.9729, -10.6786,  -6.7106, -14.7971, -11.3750,\n",
       "          -9.4117,  -9.3034,  -8.1869, -11.1227,  -9.3907,  -9.7100,  -5.7550,\n",
       "         -10.0019,  -8.5849,  -9.0706, -11.1976, -10.0834, -10.7623,  -6.3872,\n",
       "         -15.2297, -11.9506,  -9.4078, -11.1303, -11.7849, -12.1280, -10.6620,\n",
       "         -11.7635, -11.3913,  -4.0777,  -9.0462, -13.8077,  -9.1187, -10.9078,\n",
       "          -8.1056,  -4.5944,  -6.8948,  -7.3364, -13.8767,  -9.1740, -12.9978,\n",
       "         -10.0636,  -5.6396,  -5.6282, -11.9640, -12.3353,  -9.8956,  -4.2560,\n",
       "          -7.6918, -17.2577,  -7.1809, -14.2716, -12.0836, -12.2451,  -8.8942,\n",
       "          -9.0750,  -8.8601, -13.5607,  -9.3525, -12.7640,  -3.9945,  -6.7803,\n",
       "         -11.3645, -11.6174,  -7.1786, -12.4821, -11.2049, -10.4989,  -6.3022,\n",
       "         -17.5713, -12.4592, -15.2607, -10.7940,  -8.9027, -10.5757,  -7.6025,\n",
       "         -10.4217,  -7.1397, -10.7673,  -7.5496,  -8.1030,  -9.6623, -10.2253,\n",
       "         -14.4561,  -8.2009, -11.9372,  -8.3616, -11.4781, -10.5375,  -7.3965,\n",
       "         -11.3582, -10.4249,  -6.5378,  -9.8202, -14.5099,  -7.7907,  -7.5808,\n",
       "          -8.4984,  -8.2106, -13.7866,  -9.1526,  -9.2309,  -7.1742, -12.2362,\n",
       "          -8.4827,  -6.6326, -12.5417,  -6.7230, -13.8207, -14.7819, -10.5490,\n",
       "         -10.1292,  -6.6473,  -5.6440,  -9.0679,  -9.0392,  -9.4979,  -8.5176,\n",
       "          -9.6524, -20.9452, -10.4253, -14.7489, -12.4996, -10.5696, -16.3815,\n",
       "          -7.2719,  -7.8046, -11.6880,  -8.4855,  -8.0339,  -9.7712, -10.2034,\n",
       "         -10.5546,  -6.4159,  -6.0850, -14.2734, -10.8431, -10.8684, -13.9906,\n",
       "          -9.1248,  -4.8756,  -7.1760,  -8.7759,  -8.4964, -11.8524,  -9.0879,\n",
       "          -7.7146,  -7.8765,  -9.2476,  -8.5131, -11.0860,  -5.9696,  -7.6739,\n",
       "         -13.2359,  -8.6278,  -8.6910,  -7.9752,  -9.8371, -10.3789, -12.7748,\n",
       "          -7.3370,  -8.9769, -13.5363,  -8.6455,  -6.8385,  -6.7181, -17.9831,\n",
       "         -10.9345,  -7.0823, -10.6748,  -7.3809, -12.3748, -12.2728, -12.2290,\n",
       "          -8.1379, -13.9821,  -8.3359,  -4.9727, -12.6541,  -8.5059, -10.9445,\n",
       "          -8.7584, -11.9730,  -9.9145,  -9.0872,  -9.5063,  -9.3739,  -7.6614,\n",
       "          -8.2969,  -9.2243,  -7.6569,  -8.7234,  -5.5730,  -7.6802,  -9.8223,\n",
       "          -4.0004, -11.5419,  -9.6420,  -8.2221, -11.2112,  -9.5470,  -7.8289,\n",
       "         -12.9128,  -6.0208, -13.2328, -10.9800,  -8.2217,  -4.5759,  -8.0114,\n",
       "          -8.7045,  -7.8412, -10.2718,  -5.3051,  -9.4369,  -5.5303,  -8.0151,\n",
       "         -10.3451, -14.5709,  -4.5104, -10.1814,  -8.7365, -11.1058,  -8.0915,\n",
       "          -9.3106,  -7.4478,  -7.8141, -11.8070,  -6.5642, -12.4399,  -8.3672,\n",
       "          -7.6921,  -7.7777,  -7.3938,  -6.2401, -14.7794,  -8.9262,  -6.4209,\n",
       "         -10.2914,  -7.8342, -11.0328,  -9.8913, -10.5188,  -8.0516,  -9.9710,\n",
       "          -3.8444, -10.3186,  -9.1278,  -4.7626, -13.7963, -10.1074,  -6.4815,\n",
       "          -6.5509, -10.3289, -11.2257, -11.0172,  -8.4529,  -8.5907,  -7.6128,\n",
       "          -7.0552, -12.9899,  -6.9926,  -7.6044,  -8.3684,  -9.8071, -15.8119,\n",
       "         -16.3702, -10.0435,  -6.5620, -11.6666, -12.4636,  -5.6714,  -9.1784,\n",
       "          -7.1175,  -9.4208, -11.4452,  -7.8935,  -9.7861,  -4.2304,  -5.0314,\n",
       "         -11.6838, -10.3818,  -8.1439], device='cuda:0',\n",
       "        grad_fn=<NllLossBackward>),\n",
       " tensor([-10.6017,  -6.5153,  -7.7156,  -7.1300,  -8.9797, -14.8243, -10.4604,\n",
       "          -5.0886, -11.8263, -12.0110,  -8.1372,  -5.9634, -13.0777, -11.1041,\n",
       "          -8.9610, -12.0420,  -9.9264,  -7.7653, -13.1936, -12.2487,  -7.6461,\n",
       "          -9.3072,  -5.5403, -11.3645,  -4.5720, -11.8869,  -8.1555, -19.4672,\n",
       "         -13.1880,  -9.2760, -10.3665,  -7.1964,  -6.5065,  -9.0411, -12.5367,\n",
       "          -9.9833,  -6.2562,  -8.7730,  -8.3981,  -9.0166,  -7.1286,  -7.9173,\n",
       "          -9.4947,  -9.0633,  -5.4977,  -7.6318,  -4.7696,  -8.8616, -10.8872,\n",
       "         -10.7476, -11.5379,  -8.8500,  -9.0551, -10.2719,  -7.4970,  -7.8356,\n",
       "         -13.1022,  -7.7307,  -5.7404, -10.3118, -12.8673,  -9.9035,  -7.9420,\n",
       "          -9.7266,  -7.7248,  -7.0995,  -9.9996, -11.2615,  -9.0909,  -6.7004,\n",
       "         -12.0359,  -6.5071,  -9.6709, -10.7077,  -6.9993, -13.9497,  -9.3208,\n",
       "         -13.1800, -11.3742, -12.1397, -13.0965,  -9.5268,  -9.2731, -10.6690,\n",
       "         -11.7538,  -8.7562,  -9.9094,  -8.5421,  -8.8263, -14.3144, -10.3031,\n",
       "          -9.9387, -11.6634,  -8.2359, -13.3236,  -6.4368,  -2.9284, -14.7178,\n",
       "          -9.3870, -10.4109,  -6.6145, -14.0135,  -7.0668,  -5.7846,  -8.7853,\n",
       "          -6.4609, -12.1085,  -8.0164, -10.6705,  -7.7901,  -8.6129,  -8.4723,\n",
       "          -4.7658,  -5.6835, -15.0977, -12.3605, -10.5971, -11.2207, -11.3883,\n",
       "          -8.3852, -10.2601, -10.8772, -10.9879, -13.2910, -10.2752,  -8.3680,\n",
       "          -8.9159, -10.7774, -10.1183,  -5.2224,  -8.6581,  -6.8713, -13.7981,\n",
       "          -6.2530, -11.1311, -11.1821, -10.8706, -11.0464,  -9.0788,  -9.4407,\n",
       "          -7.4486,  -2.7831, -10.4379,  -6.2719,  -7.4306, -10.3620,  -8.4835,\n",
       "          -9.9409,  -6.3955, -12.6844, -10.1161,  -8.6944,  -6.9666,  -9.6767,\n",
       "          -7.9984,  -8.5300,  -8.9933, -11.6896,  -9.7038,  -8.6691, -11.8082,\n",
       "          -6.4926,  -5.4908,  -9.3549, -12.3992,  -9.4934,  -7.5158,  -9.2191,\n",
       "         -11.6804,  -5.6374,  -7.6016,  -7.1872,  -6.7682,  -9.3708, -11.0508,\n",
       "          -6.5325,  -7.8030,  -6.7760, -10.4353,  -6.4629,  -4.8815, -13.2665,\n",
       "         -16.4731, -10.4706, -14.3562, -12.4185, -14.4065, -11.5994, -13.6675,\n",
       "          -7.2190, -11.3750,  -8.0759,  -7.8013,  -9.2552,  -6.4949, -10.6643,\n",
       "         -10.8270,  -2.2479,  -7.5940, -12.8886,  -3.6348,  -9.0784,  -8.5524,\n",
       "          -8.8012, -10.0891, -11.5749,  -9.7755, -14.2787, -12.3667,  -9.6125,\n",
       "         -10.6767,  -7.5171,  -6.3239,  -6.5784,  -7.1745, -11.2282,  -9.3256,\n",
       "         -13.5378,  -8.5243,  -8.2806,  -4.1531,  -8.1139,  -8.4071, -10.9714,\n",
       "         -13.1489,  -8.5538,  -7.5393,  -7.2549,  -5.2962, -10.5522,  -7.8258,\n",
       "         -12.9568,  -8.6050, -10.0103,  -8.8573,  -8.4058, -12.3929, -11.5054,\n",
       "          -8.2001, -12.4237, -11.9119,  -6.4662,  -8.2413,  -7.9273, -11.5060,\n",
       "          -9.3729, -10.6872,  -6.4947,  -9.3525, -11.6901,  -8.0127,  -8.5603,\n",
       "          -8.0074,  -9.3473,  -8.1969, -10.8810,  -7.4459, -12.8714,  -5.6294,\n",
       "          -8.5594,  -9.3153, -11.0114,  -8.6678, -15.1141,  -8.6421,  -7.0038,\n",
       "          -6.5451,  -9.2799, -10.3691,  -7.4835,  -6.9568, -12.4484,  -8.5740,\n",
       "         -10.1212,  -7.1908,  -9.0366,  -8.3344,  -4.3184,  -7.2091, -10.2564,\n",
       "         -11.9550,  -9.7648,  -8.2052,  -5.6349, -10.5240, -10.7374,  -5.4038,\n",
       "         -10.6453,  -8.8515, -10.2710, -11.1722, -10.9616,  -9.8341,  -8.5441,\n",
       "         -11.3200, -10.4768,  -8.8963, -14.1007,  -7.0668, -12.2840,  -7.6547,\n",
       "         -10.3751, -11.5113,  -9.4838, -10.1656,  -9.0944,  -8.0396,  -6.8639,\n",
       "          -8.9397,  -9.6720,  -8.8318, -12.2185, -12.5352, -13.0536,  -9.1923,\n",
       "         -10.0202, -10.2271,  -9.4071, -12.0028,  -9.1355,  -7.6811,  -7.7416,\n",
       "          -7.0404,  -6.4739,  -6.5884,  -8.2342,  -5.5499,  -8.0423, -10.9229,\n",
       "          -9.9502,  -8.8023, -10.3024,  -4.9148, -10.2254, -11.2633,  -6.8318,\n",
       "         -17.1513,  -9.3682,  -6.6881,  -9.8565, -13.2787,  -8.4922,  -9.2580,\n",
       "         -10.1767, -10.2627, -12.8242,  -7.7879,  -9.3950, -11.0160, -15.0634,\n",
       "          -7.5936, -12.0483, -13.7240,  -7.8753,  -8.7528, -11.0035,  -9.8071,\n",
       "         -11.6058,  -9.6314,  -9.8777,  -9.6521,  -6.1445,  -8.1052, -11.7786,\n",
       "         -10.0734,  -6.8990, -15.4343,  -5.3370,  -6.1661, -16.4823,  -7.8005,\n",
       "          -8.4609,  -6.5481, -10.2203,  -9.0711, -12.4808, -10.6048, -11.5724,\n",
       "          -7.0348, -13.5733, -10.0330, -10.4443,  -7.9365, -10.8673, -10.5088,\n",
       "          -6.9579,  -8.4263, -11.8319, -10.8778,  -7.1677,  -9.9121,  -9.8210,\n",
       "          -7.4302, -10.3813,  -7.6300,  -9.1679,  -9.3757,  -7.0464,  -4.5814,\n",
       "          -8.7363,  -6.7336,  -9.6819,  -4.1209,  -9.2793,  -9.0884,  -7.0406,\n",
       "         -12.1070, -11.1635,  -6.4786,  -7.9771,  -8.4847, -14.7031,  -8.0302,\n",
       "          -7.1162,  -9.0951,  -9.1618, -10.2964,  -7.7979,  -9.9751,  -5.9365,\n",
       "         -11.8257,  -8.0122, -10.7046, -11.9416,  -5.7241,  -7.2578, -12.9207,\n",
       "          -4.2235,  -7.8001,  -8.6858,  -9.8058,  -3.5473,  -6.3505, -11.1354,\n",
       "          -9.9840,  -8.4352, -11.9091,  -6.0330, -11.4159,  -7.7233,  -7.5956,\n",
       "          -6.3926, -11.2834,  -5.5745,  -4.7529,  -9.3394,  -7.1245, -10.8251,\n",
       "          -9.0769, -10.7012,  -9.9276,  -6.6993,  -8.6483,  -9.7647, -12.7830,\n",
       "         -11.9197, -10.2658,  -9.6646,  -6.1334,  -8.0889,  -9.1184,  -5.8041,\n",
       "         -10.3261,  -9.0164,  -9.2192,  -6.6303,  -8.3395,  -7.4797,  -5.2604,\n",
       "          -5.3347,  -7.4781,  -7.9661,  -8.4236, -11.4727,  -7.8049, -14.9961,\n",
       "          -9.4744,  -7.1671,  -4.4180,  -7.0856, -11.5345, -10.4675,  -9.0305,\n",
       "          -6.5461, -12.8024,  -9.8518, -15.8620,  -6.5672, -10.5878,  -9.5465,\n",
       "         -13.0952, -13.5122, -11.8522, -11.0074,  -9.3929, -12.8623,  -8.3977,\n",
       "          -6.6451,  -6.3739,  -8.6755], device='cuda:0',\n",
       "        grad_fn=<NllLossBackward>),\n",
       " tensor([ -6.4926,  -8.0598,  -7.8995,  -7.7584,  -9.8478, -11.7908, -10.7455,\n",
       "          -8.1809,  -6.4166,  -8.6003,  -9.6388, -13.2482, -14.9918, -11.1291,\n",
       "          -4.8418,  -4.5685, -12.4160, -14.1688,  -9.9914,  -8.8034,  -7.3595,\n",
       "          -9.4759,  -7.9059, -10.2759,  -7.4365,  -4.1267,  -8.3381,  -6.2393,\n",
       "          -8.7717,  -9.4841, -11.2975,  -9.8830,  -8.3221,  -7.3414,  -8.3026,\n",
       "          -7.4867, -10.1278,  -7.6814,  -6.1467,  -3.9841,  -5.8520, -12.3944,\n",
       "          -7.9526,  -9.9041,  -7.0328,  -8.3847,  -8.2155,  -5.8618,  -4.4375,\n",
       "          -4.5378,  -7.5838,  -9.9171,  -7.3039,  -7.0934, -11.5724,  -4.9241,\n",
       "          -7.8624,  -4.3270,  -9.6621,  -6.9722, -12.7013, -15.1449,  -7.4914,\n",
       "         -11.2075, -10.8322,  -8.0558,  -8.4095,  -7.5394, -10.9566,  -5.3644,\n",
       "          -7.1619,  -6.8158,  -8.2345,  -4.1685,  -8.1055,  -9.0528,  -9.4482,\n",
       "          -8.6483,  -7.8928,  -9.1132, -11.9422,  -6.9016,  -7.0235, -12.0615,\n",
       "          -9.4438,  -6.6078,  -8.0545,  -6.1180,  -7.4970, -10.8152,  -9.4810,\n",
       "         -13.0363, -11.9221, -12.5450, -10.2855,  -8.5984,  -8.8619, -15.6432,\n",
       "         -12.0369,  -7.0559, -12.0865, -10.9447, -10.1193,  -5.4977,  -6.6832,\n",
       "          -5.9687, -11.6685,  -9.6394,  -7.8432, -12.3682, -10.5940,  -6.4891,\n",
       "          -9.9276,  -8.9968,  -8.3427, -10.3982,  -9.0814,  -8.6522,  -6.5976,\n",
       "          -8.6107, -10.0692,  -8.0263, -11.2159,  -8.4964,  -7.1142,  -9.8834,\n",
       "         -11.3371, -10.1553, -13.1976, -10.1840, -10.2733, -11.2718,  -8.3306,\n",
       "          -8.1938,  -4.9997,  -8.7674,  -4.1078, -10.4477, -15.0317,  -7.1164,\n",
       "         -12.1694, -10.0272, -10.7164,  -7.2648, -12.7215, -12.2090,  -9.6932,\n",
       "          -9.0408, -10.2557,  -5.8275,  -7.4999,  -7.7590,  -6.5884,  -9.9621,\n",
       "          -8.5608,  -7.4145, -11.2834,  -9.7851,  -5.6983,  -7.3525, -13.5376,\n",
       "          -9.4529,  -5.9966, -11.8223, -10.6689, -13.3178,  -8.0475,  -9.2763,\n",
       "          -9.8160,  -8.7597, -11.6499,  -9.8948,  -8.0210, -10.4209,  -7.8526,\n",
       "         -16.3600,  -6.5689,  -8.8846,  -8.5262, -15.2163,  -8.2627, -10.4921,\n",
       "          -8.0675, -12.8779, -14.6279,  -9.6125,  -8.7150, -16.7991,  -8.8657,\n",
       "          -7.4498,  -9.6920,  -9.7198,  -5.7089,  -9.1558,  -7.3938,  -6.9669,\n",
       "          -8.2381,  -7.9365,  -4.5232, -10.1463,  -5.7550, -10.6309,  -5.7347,\n",
       "         -12.2362,  -2.4070, -11.5899, -21.7166,  -5.6814, -11.5251,  -8.6119,\n",
       "          -7.9090,  -4.4232,  -9.6063, -10.9357, -15.3983,  -9.1677, -10.0391,\n",
       "          -6.9282,  -9.5668, -11.9565,  -7.2906, -12.0917, -10.0066, -12.6546,\n",
       "         -11.7231,  -8.5756, -15.4005,  -7.7884,  -8.9409, -13.0780, -13.0829,\n",
       "          -9.7297,  -8.4335, -11.5742, -10.5767,  -8.7528,  -9.6951,  -6.8240,\n",
       "          -7.4154,  -9.5881, -12.6549,  -9.2722, -10.9577,  -8.3518, -11.9257,\n",
       "          -8.1002,  -9.9369, -10.6883,  -4.1612,  -8.7873,  -8.7927, -11.8724,\n",
       "          -7.6660, -10.7075, -11.8810, -10.1286, -14.4022,  -9.3050,  -8.0479,\n",
       "          -7.2005,  -8.4288,  -8.8851, -11.0460,  -7.3255,  -9.2877, -11.3404,\n",
       "         -12.0481,  -9.3267, -11.1146, -10.1635,  -9.9328,  -7.8093,  -5.7682,\n",
       "          -8.8733,  -9.3168,  -8.2625, -16.4823,  -7.3911,  -4.6642, -11.7376,\n",
       "          -6.6257, -10.6515, -12.9475,  -9.2378,  -7.6022,  -9.8886,  -6.7455,\n",
       "          -9.5009, -12.7175,  -5.7831, -12.0920,  -6.6905,  -7.8799, -10.1796,\n",
       "         -10.8981, -11.6673,  -5.9367,  -6.6812,  -5.4995,  -6.2537,  -6.8980,\n",
       "         -10.2450,  -5.4699, -11.0943,  -9.0133,  -8.8366, -12.6357,  -5.4710,\n",
       "          -9.7991, -10.1896, -11.5816,  -6.6048, -11.1850,  -8.0349,  -5.4376,\n",
       "          -6.0689, -13.3958,  -8.7884,  -5.0287,  -6.3598, -11.6025,  -8.0020,\n",
       "          -9.7876,  -4.4466,  -9.1575,  -4.1829,  -9.7065,  -9.8744, -14.4642,\n",
       "         -11.6061, -13.8983, -11.1091, -11.3200, -11.3857, -13.0355, -11.7320,\n",
       "          -7.8419,  -7.4621, -10.2742,  -6.2192, -11.0714, -11.8505, -14.0439,\n",
       "         -10.4075,  -8.9680, -11.6835,  -5.3992,  -6.9540, -10.6883,  -8.4723,\n",
       "         -11.1095, -13.0326, -15.4079,  -8.5878,  -9.9687,  -5.6177, -12.6175,\n",
       "          -9.1248,  -8.9732,  -9.6567,  -8.2845,  -6.8660,  -7.6529,  -8.0741,\n",
       "          -5.7693,  -8.2206,  -9.7194, -11.1096,  -7.6174, -11.6083,  -7.7588,\n",
       "         -13.1895,  -9.2124,  -8.2033, -11.7924,  -8.3262, -11.6526,  -7.9038,\n",
       "         -16.9050, -10.6755, -10.4577,  -8.8241,  -8.4525,  -9.6020,  -6.8020,\n",
       "          -9.0785,  -8.4131,  -9.9799, -12.3498,  -8.6183, -10.3109, -10.0027,\n",
       "         -12.3505, -10.6461,  -4.7821, -11.5714, -11.1714,  -9.0818,  -9.0846,\n",
       "          -8.5384,  -6.6743, -13.0866,  -5.7754,  -8.5842, -10.4735, -11.7842,\n",
       "         -10.8165,  -6.3373, -10.5046,  -4.5720,  -7.5285,  -7.8517, -13.9849,\n",
       "          -4.9675,  -8.8453,  -8.4085,  -8.0474, -12.5278,  -5.8931, -12.1756,\n",
       "          -3.1692,  -9.5140, -10.8584,  -6.1279,  -5.4846,  -9.2761,  -6.9168,\n",
       "         -10.0859,  -7.9993,  -9.7617,  -8.3907, -14.2671,  -6.6486,  -7.7294,\n",
       "         -12.5119,  -8.3032, -10.1222, -18.1068,  -9.4997,  -9.2426, -10.2094,\n",
       "          -8.9714,  -9.4974,  -9.9603, -13.1551,  -9.5849,  -5.4572,  -7.8672,\n",
       "         -11.7716,  -8.4778, -11.5042,  -9.4303,  -6.8534, -11.1311, -13.0420,\n",
       "          -9.2825,  -8.7045,  -6.3836, -15.5767, -10.7258,  -5.6324, -12.2469,\n",
       "         -10.9471,  -8.1391,  -8.0581, -12.2083, -10.8783,  -9.3244, -11.4498,\n",
       "          -9.0904,  -8.0352,  -9.4000,  -5.2308,  -6.9232, -14.5101,  -6.5675,\n",
       "         -11.3246,  -6.2781,  -3.9346, -10.9534, -14.0394, -11.1429,  -7.1415,\n",
       "         -11.7072, -11.4961,  -7.9015,  -7.9051, -12.2125,  -9.7350, -13.3293,\n",
       "          -6.6562,  -8.2142,  -9.9401,  -9.0403, -11.6536, -13.8194,  -9.9908,\n",
       "          -6.2142,  -5.9454, -10.9629], device='cuda:0',\n",
       "        grad_fn=<NllLossBackward>),\n",
       " tensor([ -8.7676,  -3.9930,  -7.4287,  -8.8939,  -5.0030, -11.3631,  -9.5552,\n",
       "         -12.1698,  -4.9838,  -7.2824,  -8.1140,  -5.3167,  -8.7651,  -9.0584,\n",
       "          -5.6583,  -4.0555, -10.9930,  -9.1573, -12.8168, -10.2873, -13.3233,\n",
       "          -8.3708, -11.3567, -12.1153,  -9.9679,  -5.8579,  -6.7567,  -7.6466,\n",
       "          -7.6628, -10.9496, -11.4673,  -5.3789, -11.6551, -10.1328,  -5.9035,\n",
       "          -9.8019,  -7.4362,  -9.6465,  -8.6323, -12.4752,  -5.0015,  -9.5030,\n",
       "         -11.4255,  -8.3245, -10.4393,  -7.2687,  -5.2373,  -8.4236, -13.1088,\n",
       "          -9.7514, -10.2598, -11.0328,  -9.6799,  -5.7177,  -7.7035, -14.1281,\n",
       "          -8.9020,  -8.4244,  -8.8251, -10.0590, -10.3100, -10.0899,  -8.8874,\n",
       "         -11.2799,  -6.9465,  -8.3154, -14.1982,  -8.0552,  -6.5463, -10.6660,\n",
       "          -6.6091, -15.1141,  -8.9553,  -7.1527, -16.2014,  -6.0883,  -7.3837,\n",
       "          -8.2706,  -7.7506,  -6.1308,  -6.8997,  -8.5918,  -8.8188, -17.0927,\n",
       "          -9.4938,  -6.4716,  -6.6539,  -8.8459,  -6.7264,  -8.2826, -13.9255,\n",
       "          -8.5776, -11.0509, -11.3389,  -5.6636, -11.8123,  -7.0400,  -9.3414,\n",
       "         -14.0603, -11.8206, -15.7005,  -8.4198,  -8.9217, -13.0326,  -9.6646,\n",
       "         -12.9801,  -4.3646,  -5.4024, -11.1837, -10.6350, -19.4209, -11.2548,\n",
       "          -6.8325,  -4.5680,  -7.1775, -10.7681, -10.9784,  -9.6043, -14.3905,\n",
       "          -6.4671,  -3.4044,  -4.8580,  -9.7828, -14.7971, -11.4127, -11.5368,\n",
       "          -7.4059, -10.9732,  -8.0867,  -9.2588,  -9.9442, -10.5852,  -5.1301,\n",
       "          -5.9557, -13.1258,  -8.9395,  -8.7470,  -9.7060,  -8.7320,  -8.4016,\n",
       "         -11.0565,  -8.9827,  -6.7455,  -6.6786, -14.7900,  -9.7258,  -7.4140,\n",
       "          -9.3262, -14.8095, -11.7496,  -9.2667, -10.0297, -11.3028,  -8.9162,\n",
       "         -11.0508, -12.4263,  -6.7400,  -9.1875,  -6.4201,  -7.7876,  -8.9037,\n",
       "         -11.7027, -10.9282, -10.9086, -11.8644,  -9.4779, -10.2618,  -9.4833,\n",
       "          -8.2136,  -6.6950, -10.4047,  -7.4596,  -8.1789,  -4.2754,  -7.4885,\n",
       "         -13.2328, -10.3756,  -7.1905,  -6.2142, -12.6155,  -7.5314,  -8.9265,\n",
       "          -5.7962, -11.0934,  -3.5922, -13.4040, -11.5858, -11.3599,  -9.0475,\n",
       "          -4.2513, -12.3937,  -8.1275,  -7.8000,  -5.5113,  -7.4142,  -6.5739,\n",
       "         -10.9917,  -5.4979, -10.3882,  -9.2915,  -9.0909,  -5.0961,  -9.5710,\n",
       "          -4.8801, -11.7350, -10.8122, -11.2835,  -4.9404,  -7.1503, -10.7589,\n",
       "          -6.6926,  -7.7909,  -8.2461,  -8.1711, -12.1756, -11.6229,  -6.6520,\n",
       "          -9.0074,  -7.3399,  -7.4217, -10.4226,  -9.1764,  -9.6881,  -8.8387,\n",
       "         -13.2398,  -5.5196, -10.1012, -13.4965,  -7.2397,  -7.3571,  -7.8519,\n",
       "          -9.7543,  -7.9413, -10.3129,  -9.1558, -11.6954, -10.5546, -10.8358,\n",
       "          -9.1078,  -8.3023,  -9.2309,  -8.0479, -12.4800,  -5.9357,  -7.5039,\n",
       "          -7.0281,  -7.2592,  -7.6308, -10.7783,  -8.1469,  -7.5230, -15.2163,\n",
       "         -12.8805, -11.0660, -11.0271, -13.3758, -13.1835,  -7.8099,  -7.9297,\n",
       "         -11.5712, -10.2828,  -9.8204,  -7.6073,  -5.7495,  -9.5773,  -8.2815,\n",
       "          -7.3943,  -4.6369,  -8.8986,  -7.6922, -10.7144,  -9.5806, -15.2803,\n",
       "          -9.4105,  -8.6171,  -7.4391,  -8.6668, -10.8254, -11.5255,  -5.9429,\n",
       "          -6.4750,  -2.9431,  -7.6572, -12.8659,  -5.0167,  -7.6385,  -5.8467,\n",
       "         -13.3904, -10.0671,  -8.7591,  -5.9356,  -9.5581,  -6.6693,  -8.5521,\n",
       "          -8.3725,  -8.1623,  -6.5509,  -4.3791, -11.1291,  -7.7092,  -5.2612,\n",
       "         -10.1782, -10.2389,  -8.4472,  -6.8117,  -9.3559,  -8.2717,  -8.0820,\n",
       "          -8.4817,  -6.2407,  -8.7161,  -7.3378,  -8.2106, -12.7677, -12.1519,\n",
       "         -15.0458, -11.8868, -11.6584, -11.8586,  -9.7624,  -8.8318,  -7.0478,\n",
       "          -8.1110,  -8.3513,  -7.9310,  -6.5507,  -9.7023,  -6.7281,  -8.6522,\n",
       "          -8.9346, -11.5705, -14.1826,  -9.8800,  -8.8252,  -9.5155, -11.0160,\n",
       "          -7.9275,  -7.6382, -10.6115,  -9.9682,  -8.4196,  -7.8747,  -7.6215,\n",
       "          -8.9225, -13.0774,  -9.0624,  -8.3312,  -9.8494,  -7.5163,  -7.2041,\n",
       "          -9.3928,  -7.5240, -11.8937,  -9.4993,  -7.0066,  -8.4515,  -7.4702,\n",
       "          -6.6151,  -9.7034,  -8.7428,  -9.7154, -15.2534, -11.6585,  -8.4073,\n",
       "         -11.0178,  -5.2601, -13.1410,  -9.7755,  -9.5231,  -4.0958, -13.1726,\n",
       "          -7.1777, -14.3388, -10.0674,  -4.6655,  -7.5427,  -9.9607,  -7.8393,\n",
       "          -8.8121, -10.3715, -11.7979,  -9.5378,  -9.6029,  -5.6467, -13.5218,\n",
       "          -6.4444,  -8.9089,  -6.3926,  -9.4615, -14.6170, -14.0236,  -8.9041,\n",
       "          -5.0321,  -9.0117,  -8.8453,  -6.6053, -10.7428, -14.6352,  -7.5940,\n",
       "          -9.2735,  -7.2325, -10.5434, -11.9062, -10.7718,  -9.0617,  -6.8052,\n",
       "          -4.1526, -11.8006,  -8.8090,  -9.2694, -11.9276,  -5.1543, -10.1626,\n",
       "         -11.5564, -17.2080,  -9.1204, -10.1245,  -3.5473, -16.2901,  -5.3936,\n",
       "         -11.3587, -11.2207, -12.2101, -11.4177,  -4.4375, -14.6332, -11.3387,\n",
       "          -8.1346,  -5.6027, -10.5307,  -3.6884, -12.2304,  -9.0788,  -2.8875,\n",
       "         -16.9930, -11.4211, -15.3576,  -7.4930,  -9.1802, -10.0268,  -4.9922,\n",
       "         -10.0822,  -9.0634,  -8.8371,  -9.8130,  -8.2226,  -9.4647, -13.3775,\n",
       "          -9.8115,  -7.3903, -13.3754,  -7.8407, -13.1800, -11.5199,  -6.5136,\n",
       "         -13.5317,  -8.7630, -12.2497,  -7.7155, -17.3092,  -6.4500, -10.1269,\n",
       "          -4.3007,  -8.4848, -11.3987,  -9.8643, -15.6651,  -8.5122,  -8.2762,\n",
       "          -7.2042,  -5.3424,  -8.6720, -10.0982,  -7.3053,  -7.5115,  -9.3866,\n",
       "          -9.5318, -11.8944,  -7.6765,  -8.4739, -11.1014,  -8.6245,  -9.2621,\n",
       "          -9.7295,  -9.6818,  -5.9869, -10.9757, -11.1866,  -9.6637,  -9.5579,\n",
       "          -8.2987,  -9.7133, -12.9278, -10.8590,  -6.3302,  -8.5561,  -8.7707,\n",
       "         -10.1163, -10.0316,  -9.5461], device='cuda:0',\n",
       "        grad_fn=<NllLossBackward>),\n",
       " tensor([ -8.9614, -11.7615, -13.0688, -10.4922, -11.9980, -12.2311,  -8.4262,\n",
       "          -6.2241,  -9.2525,  -8.8429, -13.0749, -11.0522,  -7.5039,  -7.8333,\n",
       "          -7.1988,  -3.3242, -11.6517, -11.0253,  -9.7297,  -8.7897,  -4.2454,\n",
       "          -6.8394,  -8.8162, -10.7404,  -8.5407,  -8.6914,  -8.3708, -13.2773,\n",
       "         -11.5372, -13.4531,  -8.7036, -15.2373,  -6.1183,  -8.9546,  -6.5669,\n",
       "         -13.4660,  -7.9413,  -7.8470, -10.0828, -10.0789,  -8.7811,  -8.9750,\n",
       "         -10.3401,  -6.8307, -12.6733,  -7.2352, -16.6902,  -7.7968,  -9.4986,\n",
       "          -8.6398,  -5.7376, -11.8946, -12.4079,  -8.0725,  -5.2906,  -6.4645,\n",
       "         -10.3982, -10.9467,  -8.4337,  -9.8500,  -8.4927,  -9.4134,  -8.0743,\n",
       "          -4.4564,  -7.1740, -10.6417, -10.2306,  -3.4228,  -4.3802,  -6.5690,\n",
       "          -6.8710,  -9.4742,  -8.9869,  -9.3058,  -4.1041, -12.7446, -10.3033,\n",
       "          -5.3777, -10.4893,  -8.6158, -10.6975,  -9.7896,  -7.7188, -10.4974,\n",
       "          -9.4863, -12.7571, -10.0318,  -8.4145, -11.3263,  -8.8743, -10.2926,\n",
       "         -14.7298,  -8.1705, -12.5232,  -8.3152,  -4.1696, -12.3275,  -6.9540,\n",
       "         -12.2160, -12.1960, -12.6294,  -7.1677,  -8.9225, -12.3973, -10.3248,\n",
       "          -9.4416, -12.3018,  -4.1813,  -5.7388,  -9.5600,  -9.1016,  -6.1492,\n",
       "         -10.6643,  -6.8601,  -4.0796, -14.0707,  -8.7251,  -5.4710, -10.8413,\n",
       "         -11.9436,  -3.3607, -14.4925,  -5.8367, -11.3183,  -3.9441,  -5.4990,\n",
       "          -9.3900,  -6.8941, -13.1169,  -9.1835,  -8.6615, -10.1501,  -5.0796,\n",
       "          -7.2468, -12.8879,  -9.2848, -10.3434,  -4.6686, -13.9935, -10.6673,\n",
       "          -7.6457, -12.8744,  -9.6147, -10.9936, -15.0458,  -6.1308,  -7.8624,\n",
       "         -12.5026, -11.2064,  -9.2731,  -6.3673,  -6.8367,  -6.3029,  -7.4450,\n",
       "          -9.4071, -10.6786,  -8.6486,  -5.5731,  -6.3840, -10.0025,  -6.2347,\n",
       "         -10.1253,  -7.9666, -11.4214, -17.1698, -10.7012,  -9.2547,  -9.1935,\n",
       "         -14.7354,  -8.4050,  -8.9919,  -8.7428,  -8.1602,  -9.7149, -14.5494,\n",
       "          -6.4771, -12.5250,  -8.3616,  -8.6478,  -8.6324,  -9.0573,  -7.5071,\n",
       "          -9.9750,  -7.9398,  -7.8098, -13.0866,  -6.4810,  -9.0711,  -7.2373,\n",
       "          -7.1245, -10.7133,  -8.0670,  -8.1485, -12.9763, -11.4928, -11.3905,\n",
       "          -8.4453,  -7.0674,  -9.5320, -10.0700, -11.5764,  -8.2484,  -7.3175,\n",
       "          -6.1857, -10.3002, -10.7126,  -5.5521,  -5.9188, -10.0731, -10.3336,\n",
       "          -9.5919,  -8.3895,  -6.4771,  -7.6631,  -8.8453,  -7.2843, -11.9199,\n",
       "          -3.1692,  -7.9866, -12.0227,  -7.6194,  -9.9313,  -9.6697,  -8.1009,\n",
       "         -11.3101,  -7.5933, -16.9134, -11.7538,  -9.1224,  -5.2477,  -6.7258,\n",
       "          -5.9866, -10.2535, -11.6307,  -9.5437,  -5.8267,  -4.1072, -11.2171,\n",
       "          -8.2943, -12.7463, -11.2877, -11.4889,  -9.4569, -11.5858, -10.0312,\n",
       "          -7.7737,  -8.0510,  -7.2778,  -9.0453,  -5.6770,  -9.5519, -11.3090,\n",
       "          -9.0472, -12.6661, -19.1989,  -7.0753, -17.7434,  -7.2625,  -5.2298,\n",
       "          -5.8370,  -8.6487,  -7.2648, -11.3177,  -6.9586,  -5.9658,  -8.9494,\n",
       "         -10.3270,  -9.8617, -12.9448,  -6.1163, -11.7842,  -9.8261, -10.1934,\n",
       "         -11.0443, -11.5899,  -5.5083,  -9.5864,  -8.9159, -10.2133, -16.5678,\n",
       "         -14.8947, -10.9301,  -7.9743, -15.6346, -11.7146, -11.3626, -11.8752,\n",
       "          -4.5801, -12.8732,  -4.3423, -13.4378,  -6.1103,  -8.4710,  -9.6651,\n",
       "         -12.3051,  -8.7730, -10.2778,  -8.0352, -12.7072, -11.7752, -11.3460,\n",
       "          -9.4369,  -9.4682, -10.2892, -16.4201,  -5.8511,  -8.0581, -10.9245,\n",
       "         -13.8850,  -8.0020, -10.1509,  -9.2978, -10.4894, -11.2314,  -7.1071,\n",
       "          -9.5034, -10.1635,  -4.5987,  -7.5759, -10.8378,  -9.8670,  -9.7628,\n",
       "          -9.5098,  -9.0591, -13.7805,  -5.5531,  -5.6607,  -9.9606,  -7.3918,\n",
       "          -7.3837,  -8.8193,  -3.4140,  -9.4627,  -9.1437, -12.6251, -10.6643,\n",
       "         -13.6817,  -7.0536,  -8.6897,  -9.6296,  -6.8272,  -9.9408,  -8.1441,\n",
       "          -8.8256, -14.4406, -11.9911,  -5.7007, -10.1024,  -4.9636,  -9.2391,\n",
       "         -13.0442, -14.3748, -11.4862,  -7.3914, -11.8606, -10.0916,  -8.3951,\n",
       "          -8.7356,  -6.8827,  -6.9228,  -7.6275,  -9.4508, -10.0811,  -7.5214,\n",
       "         -10.1151,  -9.8919,  -9.6002,  -6.6891,  -7.7157,  -8.9253,  -6.2738,\n",
       "          -8.1749, -11.1178, -10.8731, -12.1819,  -2.8250,  -9.3921,  -9.2042,\n",
       "          -8.7245, -10.9137, -14.3388, -10.7961, -10.8391, -10.1712,  -9.9805,\n",
       "          -8.6305,  -8.2775, -10.8134, -13.6134,  -9.4472, -12.3656,  -9.9059,\n",
       "          -6.6047, -10.2383,  -6.7693,  -8.5271, -11.5656, -15.0428, -16.0706,\n",
       "          -8.2764,  -8.9838,  -8.4470,  -5.3348,  -8.3694, -12.3408, -10.0888,\n",
       "          -9.9249,  -7.9004, -13.1627,  -7.5977, -10.2094, -14.3602,  -8.7916,\n",
       "          -8.6944, -11.5710,  -9.6857,  -8.0197,  -6.8018,  -6.9081,  -9.6298,\n",
       "         -10.1121,  -8.4538,  -8.3461,  -7.1307, -11.2852, -12.8516,  -6.2571,\n",
       "         -12.2840, -15.3836, -10.6556, -11.2165,  -8.5601,  -9.5763,  -8.1769,\n",
       "          -8.6051, -10.0331, -13.4415,  -6.6374, -18.5355,  -4.5719,  -8.7343,\n",
       "          -8.7154,  -7.4455, -11.0576,  -7.3039, -11.1717,  -8.8619, -10.2759,\n",
       "          -9.9488, -13.1741,  -9.8312, -19.0873,  -9.5806, -12.4624,  -7.1728,\n",
       "          -6.5950, -10.3710,  -7.9579,  -6.4926, -10.6434, -11.0934,  -9.9145,\n",
       "          -7.7836,  -7.1107,  -7.1711,  -6.4542,  -8.4568, -16.8192,  -8.1856,\n",
       "          -8.1751,  -7.3762,  -3.7296, -13.0264,  -6.4918, -11.3845, -14.2086,\n",
       "          -9.8732,  -5.9554,  -3.2408, -19.5742,  -5.6907, -12.0769, -10.0652,\n",
       "         -11.8941, -11.0542, -14.2332, -11.0628,  -7.2641, -11.7098, -12.2751,\n",
       "          -9.0885, -13.5731,  -8.8035, -11.7755,  -8.8577,  -9.8333,  -8.5906,\n",
       "         -10.1839,  -9.0532, -11.5079], device='cuda:0',\n",
       "        grad_fn=<NllLossBackward>),\n",
       " tensor([ -8.1691, -10.7225,  -4.0161, -10.1070,  -8.0218, -10.0822,  -7.5162,\n",
       "          -6.4965,  -6.7981,  -3.6942, -11.4599,  -7.8753, -10.0845,  -4.9205,\n",
       "          -7.1872, -14.0761,  -8.7169, -12.4715, -11.2225,  -5.8298,  -4.7225,\n",
       "          -9.4342,  -6.6897,  -9.2779, -11.5180,  -7.4362,  -6.3839,  -8.3217,\n",
       "          -8.8963,  -9.2028,  -6.6383, -11.9622,  -9.5977,  -6.7367,  -7.8382,\n",
       "          -7.6572, -16.5290,  -8.5119,  -7.6091, -10.7186,  -8.4842,  -8.9298,\n",
       "          -8.4408,  -4.5801,  -9.2336,  -6.1217,  -9.1348,  -7.6214, -11.6672,\n",
       "         -10.6935, -11.6538, -10.5567,  -9.6959,  -9.6355, -12.6069,  -8.4583,\n",
       "         -12.4065,  -7.9761,  -8.7873,  -7.9827, -10.0638, -14.6340,  -6.9439,\n",
       "         -10.8763,  -9.4185, -11.0629, -13.2771,  -9.7095,  -9.3523, -11.2097,\n",
       "          -8.0105,  -9.5137,  -6.2449,  -5.5499, -12.5080, -10.8257, -13.1877,\n",
       "         -14.1514, -10.1452, -10.6638,  -9.0438,  -7.8717, -16.1628,  -6.8549,\n",
       "          -7.8633, -10.5670,  -6.2489,  -9.3512,  -6.7500,  -7.0348,  -7.7995,\n",
       "         -14.7937,  -8.6825, -10.0634, -11.7127,  -5.3829,  -9.5159, -13.3775,\n",
       "          -8.2737,  -9.8569, -11.4287,  -5.1822,  -9.7722,  -7.0814, -13.3574,\n",
       "          -5.7939, -11.5135,  -6.6197,  -6.1006, -11.6934, -13.4573, -11.0542,\n",
       "          -9.0602,  -7.0364, -11.3074, -12.1358,  -9.5645,  -7.5922, -11.3703,\n",
       "         -12.3642,  -7.3975,  -8.0464,  -5.2319,  -8.9667,  -6.2679, -10.9713,\n",
       "          -8.1049, -15.5561,  -8.0832,  -8.5746, -11.0216, -11.7545,  -9.5202,\n",
       "          -9.0891,  -9.4453,  -9.9753,  -9.6481,  -8.0754, -11.4746, -11.6458,\n",
       "         -10.9726,  -6.1332,  -8.3701,  -8.4695,  -7.0176, -10.1058,  -9.6767,\n",
       "         -11.6388,  -5.7843, -11.1719, -14.2065,  -8.4214,  -6.5778,  -7.8537,\n",
       "          -9.3804,  -9.3433, -14.2915, -15.8632,  -9.4249, -11.6954, -12.9077,\n",
       "          -7.2310,  -9.3832,  -6.3211, -12.4649, -12.3867,  -6.0242, -11.5052,\n",
       "         -11.2047,  -7.8590,  -9.0694, -12.0255, -10.2446, -10.8620,  -4.8043,\n",
       "          -7.5100,  -6.7957,  -8.6615, -12.6294, -11.9276,  -7.4702,  -6.7731,\n",
       "          -9.8058, -10.6350,  -7.2979,  -9.7380,  -8.3475, -10.0891,  -8.9390,\n",
       "          -8.7299, -13.6745,  -8.4351,  -7.6093, -11.6966, -13.3755,  -7.5750,\n",
       "         -11.0687,  -5.0172,  -9.1494, -10.5010,  -7.9936, -10.8346, -14.1222,\n",
       "         -17.7969, -14.0147,  -8.1483, -12.8025,  -8.3714,  -7.1187, -10.6359,\n",
       "         -12.7562, -11.0578, -14.5442, -10.1807,  -4.5055, -12.4952, -11.1501,\n",
       "         -10.5931,  -9.6011, -11.6344,  -5.4836, -11.9568, -10.0387, -10.0977,\n",
       "         -12.1552,  -4.0576, -10.4735,  -5.8714, -13.4681, -10.8140,  -9.5715,\n",
       "         -14.2073, -10.3571,  -8.9750,  -4.1643, -15.3402, -10.1912,  -9.8783,\n",
       "          -7.4939, -11.4412,  -7.0248, -11.2786,  -9.6584, -20.0739,  -8.4374,\n",
       "          -8.7849, -12.3146,  -9.5424,  -7.3552,  -9.0834, -14.6943, -12.2750,\n",
       "         -11.8756,  -9.2480, -11.4833, -11.2834,  -8.4953,  -9.9355,  -9.8130,\n",
       "          -6.3703, -10.8068, -10.0501,  -7.9277,  -9.9131, -12.1418, -13.8002,\n",
       "          -8.9109, -13.5021,  -4.5361, -13.5923,  -8.9133,  -6.9726,  -8.2204,\n",
       "          -9.5589,  -7.3851,  -8.7241,  -8.4169, -11.2774,  -8.9948,  -8.6434,\n",
       "         -12.0652,  -9.9303,  -7.6300,  -9.1710,  -8.5300,  -9.7175,  -8.5779,\n",
       "          -7.5863, -11.4971,  -9.8318,  -4.8024, -10.6662,  -8.9769, -10.1081,\n",
       "         -10.0488,  -9.3026, -10.1819,  -8.3667, -10.6723, -16.1180,  -4.6328,\n",
       "         -11.9730,  -9.6870,  -4.9905, -11.7717,  -5.6396,  -9.1981, -11.0495,\n",
       "          -5.8420, -12.9062, -12.4064,  -8.2262,  -7.1526, -16.8186,  -7.8275,\n",
       "         -13.4091, -12.9803,  -7.7329,  -8.4143,  -8.9815,  -5.1857,  -8.1630,\n",
       "         -12.5788,  -8.5812,  -9.9497,  -8.2109,  -7.3244,  -4.9961, -10.4002,\n",
       "          -7.7445, -11.2957,  -8.5522,  -6.5049, -12.4624, -14.7407, -12.0028,\n",
       "          -8.8022,  -6.8889, -10.2217,  -6.6674,  -6.9327,  -6.5253,  -9.8436,\n",
       "         -11.2069, -12.7211, -10.8381, -11.0962,  -7.9158, -10.0327,  -7.5230,\n",
       "         -10.7262,  -7.6473, -10.4209,  -5.7272,  -9.5806,  -9.9800,  -9.6152,\n",
       "          -4.7513, -11.1429, -11.3666, -10.4209,  -7.9071,  -5.2811,  -7.3234,\n",
       "          -5.7954, -14.7913,  -9.9237,  -9.9731,  -5.5820,  -9.8699, -13.2521,\n",
       "         -11.6757,  -8.5852, -13.2062,  -7.7478,  -8.7215, -10.4056,  -6.2719,\n",
       "          -8.3354,  -9.3357,  -9.3014, -10.1024, -12.3973,  -5.5128,  -8.2716,\n",
       "          -8.5318,  -7.9568, -10.0524, -10.8229, -11.1818, -10.5439, -11.8705,\n",
       "          -6.7026, -10.1514,  -4.1408, -10.6310, -10.7071, -13.7172, -10.9959,\n",
       "          -7.5513,  -7.3418,  -5.8359, -10.5427,  -7.7653, -12.7441, -11.4043,\n",
       "          -4.7727,  -7.8795,  -5.8350,  -9.5123,  -6.4862,  -9.7525, -11.3156,\n",
       "         -10.3033,  -5.9746,  -6.1692,  -7.1100, -10.9708, -10.1520,  -9.9743,\n",
       "         -19.2074, -10.7612,  -9.6397, -10.7395, -12.5503,  -6.7574, -17.9570,\n",
       "          -8.4444, -14.4891,  -8.3740, -10.3910, -10.4013, -11.2887,  -9.6857,\n",
       "          -8.9583,  -7.5438,  -9.0749,  -9.1924, -17.0701,  -7.7582,  -9.2426,\n",
       "          -7.7495,  -7.7998, -11.0460,  -8.0677,  -8.1696,  -8.4764,  -4.8670,\n",
       "          -7.0249, -10.7358, -12.2137, -13.1090,  -8.1867,  -6.5729,  -6.2303,\n",
       "          -6.4623,  -9.2632, -11.2933, -10.1999, -16.7724,  -6.6583,  -6.7023,\n",
       "          -6.5300, -15.1426,  -8.7216,  -7.0169, -10.7459, -10.7310,  -9.0814,\n",
       "          -8.7666,  -9.9765,  -9.8626, -10.3921, -11.4919, -11.4575, -16.9930,\n",
       "          -6.2774,  -9.0642,  -9.0623, -12.8173,  -8.0010,  -5.4808,  -8.4722,\n",
       "         -11.4956, -13.1788, -17.1643,  -9.0421, -13.0911, -13.6826,  -6.9553,\n",
       "          -9.2948,  -2.9431,  -4.8784,  -6.1161,  -8.2100, -10.9287, -11.1806,\n",
       "         -10.6769, -11.4205,  -8.1052], device='cuda:0',\n",
       "        grad_fn=<NllLossBackward>)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[logs_adv[id]['metric_loss'] for id in (victim_idxs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2227/3056046577.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mid\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvictim_idxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "for id in len(victim_idxs):\n",
    "    print(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
