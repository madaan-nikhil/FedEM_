{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FedEM Attack Analysis\n",
    "\n",
    "TJ Kim\n",
    "11.5.21\n",
    "\n",
    "#### Summary:\n",
    "- Load the locally trained model and FedEM model\n",
    "- nodes = 3, mixtures = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/FedEM\n"
     ]
    }
   ],
   "source": [
    "cd /home/ubuntu/FedEM/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Relevant Libraries\n",
    "Take it from the run_experiment.py folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import General Libraries\n",
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "import copy\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Import FedEM based Libraries\n",
    "from utils.utils import *\n",
    "from utils.constants import *\n",
    "from utils.args import *\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from run_experiment import *\n",
    "from models import *\n",
    "\n",
    "# Import Transfer Attack\n",
    "from transfer_attacks.Personalized_NN import *\n",
    "from transfer_attacks.Params import *\n",
    "from transfer_attacks.Transferer import *\n",
    "from transfer_attacks.Args import *\n",
    "\n",
    "from transfer_attacks.TA_utils import *\n",
    "from transfer_attacks.Boundary_Transferer import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Aggregator Pre-requisite\n",
    "- Clients, Test Clients, Ensemble_Learner\n",
    "- Follow through the code in run_experiment.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Clients initialization..\n",
      "===> Building data iterators..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 80/80 [00:00<00:00, 185.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Initializing clients..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 80/80 [00:33<00:00,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Test Clients initialization..\n",
      "===> Building data iterators..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Initializing clients..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++\n",
      "Global..\n",
      "Train Loss: 2.292 | Train Acc: 12.195% |Test Loss: 2.292 | Test Acc: 12.291% |\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "################################################################################\n"
     ]
    }
   ],
   "source": [
    "# Manually set argument parameters\n",
    "args_ = Args()\n",
    "args_.experiment = \"cifar10\"\n",
    "args_.method = \"FedEM\"\n",
    "args_.decentralized = False\n",
    "args_.sampling_rate = 1.0\n",
    "args_.input_dimension = None\n",
    "args_.output_dimension = None\n",
    "args_.n_learners= 3\n",
    "args_.n_rounds = 10\n",
    "args_.bz = 128\n",
    "args_.local_steps = 1\n",
    "args_.lr_lambda = 0\n",
    "args_.lr =0.03\n",
    "args_.lr_scheduler = 'multi_step'\n",
    "args_.log_freq = 10\n",
    "args_.device = 'cpu'\n",
    "args_.optimizer = 'sgd'\n",
    "args_.mu = 0\n",
    "args_.communication_probability = 0.1\n",
    "args_.q = 1\n",
    "args_.locally_tune_clients = False\n",
    "args_.seed = 1234\n",
    "args_.verbose = 1\n",
    "args_.save_path = 'weights/cifar/21_12_30_feddef2_n40_linf0_5/'\n",
    "args_.validation = False\n",
    "\n",
    "# Generate the dummy values here\n",
    "aggregator, clients = dummy_aggregator(args_, num_user=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_client_data(clients, c_id, mode = 'test'):\n",
    "    \n",
    "    data_x = []\n",
    "    data_y = []\n",
    "\n",
    "    if mode == 'all': # load all validation sets together\n",
    "        for i in range(len(clients)):\n",
    "            daniloader = clients[i].val_iterator\n",
    "            for (x,y,idx) in daniloader.dataset:\n",
    "                data_x.append(x)\n",
    "                data_y.append(y)\n",
    "    else:\n",
    "        if mode == 'train':\n",
    "            daniloader = clients[c_id].train_iterator\n",
    "        if mode == 'val':\n",
    "            daniloader = clients[c_id].val_iterator\n",
    "        else:\n",
    "            daniloader = clients[c_id].test_iterator\n",
    "\n",
    "        for (x,y,idx) in daniloader.dataset:\n",
    "            data_x.append(x)\n",
    "            data_y.append(y)\n",
    "\n",
    "    data_x = torch.stack(data_x)\n",
    "    data_y = torch.stack(data_y)        \n",
    "\n",
    "    dataloader = Custom_Dataloader(data_x, data_y)\n",
    "    \n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MobileNetV2(\n",
       "  (features): Sequential(\n",
       "    (0): ConvBNReLU(\n",
       "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6(inplace=True)\n",
       "    )\n",
       "    (1): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (3): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (4): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (7): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (8): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (9): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (10): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (11): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (12): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (13): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (14): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (15): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (16): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (17): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (18): ConvBNReLU(\n",
       "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.2, inplace=False)\n",
       "    (1): Linear(in_features=1280, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clients[0].learners_ensemble.learners[0].model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "776"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader = load_client_data(clients, 2, mode = \"val\")\n",
    "dataloader.y_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine Validation Data across all clients as test\n",
    "data_x = []\n",
    "data_y = []\n",
    "\n",
    "for i in range(len(clients)):\n",
    "    daniloader = clients[i].val_iterator\n",
    "    for (x,y,idx) in daniloader.dataset:\n",
    "        data_x.append(x)\n",
    "        data_y.append(y)\n",
    "\n",
    "data_x = torch.stack(data_x)\n",
    "data_y = torch.stack(data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataloader from validation dataset that allows for diverse batch size\n",
    "dataloader = Custom_Dataloader(data_x, data_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model of specific type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change name if need be\n",
    "args_.save_path = 'weights/cifar/21_12_30_feddef_n40_linf0_5/'\n",
    "\n",
    "# Import weights for aggregator\n",
    "aggregator.load_state(args_.save_path)\n",
    "\n",
    "# This is where the models are stored -- one for each mixture --> learner.model for nn\n",
    "hypotheses = aggregator.global_learners_ensemble.learners\n",
    "\n",
    "# obtain the state dict for each of the weights \n",
    "weights_h = []\n",
    "\n",
    "for h in hypotheses:\n",
    "    weights_h += [h.model.state_dict()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_name = args_.save_path + 'train_client_weights.npy'\n",
    "weights = np.load(weight_name)\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.2f}\".format(x)})\n",
    "\n",
    "#print(weights)\n",
    "\n",
    "# Set model weights\n",
    "model_weights = []\n",
    "num_models = 40\n",
    "\n",
    "for i in range(num_models):\n",
    "    model_weights += [weights[i]]\n",
    "    \n",
    "    \n",
    "# Generate the weights to test on as linear combinations of the model_weights\n",
    "models_test = []\n",
    "\n",
    "for (w0,w1,w2) in model_weights:\n",
    "    # first make the model with empty weights\n",
    "    new_model = copy.deepcopy(hypotheses[0].model)\n",
    "    new_model.eval()\n",
    "    new_weight_dict = copy.deepcopy(weights_h[0])\n",
    "    for key in weights_h[0]:\n",
    "        new_weight_dict[key] = w0*weights_h[0][key] + w1*weights_h[1][key] + w2*weights_h[2][key]\n",
    "    new_model.load_state_dict(new_weight_dict)\n",
    "    models_test += [new_model]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Up Transfer Attack Scenario\n",
    "- Set up order of which attacks will take place -- keep the same transferer, but simply swap out the weights of the adversary and flush out the existing data points analysis was done on\n",
    "- Make dictionaries beforehand recording all of the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Up Dictionaries -- list holds the adversary idx\n",
    "logs_adv = []\n",
    "\n",
    "for i in range(len(model_weights)):\n",
    "    adv_dict = {}\n",
    "    adv_dict['orig_acc_transfers'] = None\n",
    "    adv_dict['orig_similarities'] = None\n",
    "    adv_dict['adv_acc_transfers'] = None\n",
    "    adv_dict['adv_similarities'] = None\n",
    "    adv_dict['orig_target_hit'] = None\n",
    "    adv_dict['adv_target_hit'] = None\n",
    "    adv_dict['metric_variance'] = None\n",
    "    adv_dict['metric_alignment'] = None\n",
    "    adv_dict['metric_ingrad'] = None\n",
    "    logs_adv += [adv_dict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id 0\n",
      "id 1\n",
      "id 2\n",
      "id 3\n",
      "id 4\n",
      "id 5\n",
      "id 6\n"
     ]
    }
   ],
   "source": [
    "# Make transferer and Assign model index\n",
    "victim_idxs =[0,1,2,3,4,5,6]# [0,41,42,43,44,45,46] #  Include other models for analysis?\n",
    "custom_batch_size = 500\n",
    "\n",
    "for adv_idx in victim_idxs:\n",
    "    print(\"id\", adv_idx)\n",
    "    # Perform Attack\n",
    "    \n",
    "    # Import client dataloader here (aka. adv_idx)\n",
    "    dataloader = load_client_data(clients, c_id, mode = 'val') # or test/train\n",
    "    t1 = Transferer(models_list=models_test, dataloader=dataloader)\n",
    "    \n",
    "    batch_size = min(custom_batch_size, dataloader.y_data.shape[0])\n",
    "    \n",
    "    # atk Params setup\n",
    "    t1.atk_params.set_params(batch_size=batch_size, eps=0.1, alpha=0.05, iteration = 30,\n",
    "                   target = 5, x_val_min = torch.min(data_x), x_val_max = torch.max(data_x))\n",
    "    \n",
    "    t1.atk_params = PGD_Params()\n",
    "    t1.atk_params.set_params(batch_size=batch_size, iteration = 30,\n",
    "                   target = 5, x_val_min = torch.min(data_x), x_val_max = torch.max(data_x),\n",
    "                   step_size = 0.05, step_norm = \"inf\", eps = 0.4, eps_norm = \"inf\")\n",
    "\n",
    "    \n",
    "    t1.generate_victims(victim_idxs)\n",
    "    t1.generate_advNN(adv_idx)\n",
    "    t1.generate_xadv(atk_type = \"pgd\")\n",
    "    t1.send_to_victims(victim_idxs)\n",
    "    # t1.check_empirical_metrics(orig_flag = True)\n",
    "    # t1.check_empirical_metrics()\n",
    "    \n",
    "    # Log Performance\n",
    "    logs_adv[adv_idx]['orig_acc_transfers'] = t1.orig_acc_transfers\n",
    "    logs_adv[adv_idx]['orig_similarities'] = t1.orig_similarities\n",
    "    logs_adv[adv_idx]['adv_acc_transfers'] = t1.adv_acc_transfers\n",
    "    logs_adv[adv_idx]['adv_similarities'] = t1.adv_similarities\n",
    "    logs_adv[adv_idx]['orig_target_hit'] = t1.orig_target_hit\n",
    "    logs_adv[adv_idx]['adv_target_hit'] = t1.adv_target_hit\n",
    "    \n",
    "    logs_adv[adv_idx]['metric_variance'] = t1.metric_variance\n",
    "    logs_adv[adv_idx]['metric_alignment'] = t1.metric_alignment\n",
    "    logs_adv[adv_idx]['metric_ingrad'] = t1.metric_ingrad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print and Record Results\n",
    "- Organize the results into a matrix and print them into an excel sheet\n",
    "- Following Categories (sim_benign, sim_adv, target_adv,grad_alignment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['orig_acc_transfers','orig_similarities','adv_similarities','adv_target_hit','metric_alignment']\n",
    "\n",
    "orig_acc = np.zeros([len(victim_idxs),len(victim_idxs)]) \n",
    "sim_benign = np.zeros([len(victim_idxs),len(victim_idxs)]) \n",
    "sim_adv = np.zeros([len(victim_idxs),len(victim_idxs)]) \n",
    "target_adv = np.zeros([len(victim_idxs),len(victim_idxs)]) \n",
    "# grad_align = np.zeros([len(victim_idxs),len(victim_idxs)]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for adv_idx in range(len(victim_idxs)):\n",
    "    for victim in range(len(victim_idxs)):\n",
    "        orig_acc[adv_idx,victim] = logs_adv[victim_idxs[adv_idx]][metrics[0]][victim_idxs[victim]].data.tolist()\n",
    "        sim_benign[adv_idx,victim] = logs_adv[victim_idxs[adv_idx]][metrics[1]][victim_idxs[victim]].data.tolist()\n",
    "        sim_adv[adv_idx,victim] = logs_adv[victim_idxs[adv_idx]][metrics[2]][victim_idxs[victim]].data.tolist()\n",
    "        target_adv[adv_idx,victim] = logs_adv[victim_idxs[adv_idx]][metrics[3]][victim_idxs[victim]].data.tolist()\n",
    "#         grad_align[adv_idx,victim] = logs_adv[adv_idx][metrics[4]][victim].data.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to Excel file\n",
    "\n",
    "## convert your array into a dataframe\n",
    "orig_acc_df = pd.DataFrame(orig_acc)\n",
    "sim_benign_df = pd.DataFrame(sim_benign)\n",
    "sim_adv_df = pd.DataFrame(sim_adv)\n",
    "target_adv_df = pd.DataFrame(target_adv)\n",
    "# grad_align_df = pd.DataFrame(grad_align)\n",
    "\n",
    "## save to xlsx file\n",
    "\n",
    "#filepath = 'my_excel_file.xlsx'\n",
    "\n",
    "# df.to_excel(filepath, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.662</td>\n",
       "      <td>0.798</td>\n",
       "      <td>0.718</td>\n",
       "      <td>0.670</td>\n",
       "      <td>0.638</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.672</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.728</td>\n",
       "      <td>0.668</td>\n",
       "      <td>0.672</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.726</td>\n",
       "      <td>0.798</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.692</td>\n",
       "      <td>0.664</td>\n",
       "      <td>0.756</td>\n",
       "      <td>0.764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.668</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.722</td>\n",
       "      <td>0.682</td>\n",
       "      <td>0.632</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.698</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.740</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0.640</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.690</td>\n",
       "      <td>0.730</td>\n",
       "      <td>0.718</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.646</td>\n",
       "      <td>0.726</td>\n",
       "      <td>0.730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.700</td>\n",
       "      <td>0.770</td>\n",
       "      <td>0.734</td>\n",
       "      <td>0.674</td>\n",
       "      <td>0.648</td>\n",
       "      <td>0.752</td>\n",
       "      <td>0.752</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1      2      3      4      5      6\n",
       "0  0.662  0.798  0.718  0.670  0.638  0.738  0.750\n",
       "1  0.672  0.750  0.728  0.668  0.672  0.738  0.740\n",
       "2  0.726  0.798  0.750  0.692  0.664  0.756  0.764\n",
       "3  0.668  0.768  0.722  0.682  0.632  0.738  0.738\n",
       "4  0.698  0.780  0.740  0.680  0.640  0.754  0.764\n",
       "5  0.690  0.730  0.718  0.676  0.646  0.726  0.730\n",
       "6  0.700  0.770  0.734  0.674  0.648  0.752  0.752"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_acc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.756</td>\n",
       "      <td>0.858</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.776</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.886</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.566</td>\n",
       "      <td>0.906</td>\n",
       "      <td>0.912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.856</td>\n",
       "      <td>0.882</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.612</td>\n",
       "      <td>0.538</td>\n",
       "      <td>0.976</td>\n",
       "      <td>0.964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.574</td>\n",
       "      <td>0.664</td>\n",
       "      <td>0.626</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.746</td>\n",
       "      <td>0.622</td>\n",
       "      <td>0.634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.496</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.734</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.862</td>\n",
       "      <td>0.894</td>\n",
       "      <td>0.970</td>\n",
       "      <td>0.586</td>\n",
       "      <td>0.504</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.852</td>\n",
       "      <td>0.904</td>\n",
       "      <td>0.962</td>\n",
       "      <td>0.626</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.990</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1      2      3      4      5      6\n",
       "0  1.000  0.756  0.858  0.556  0.510  0.820  0.810\n",
       "1  0.776  1.000  0.886  0.636  0.566  0.906  0.912\n",
       "2  0.856  0.882  1.000  0.612  0.538  0.976  0.964\n",
       "3  0.574  0.664  0.626  1.000  0.746  0.622  0.634\n",
       "4  0.496  0.550  0.514  0.734  1.000  0.514  0.514\n",
       "5  0.862  0.894  0.970  0.586  0.504  1.000  0.984\n",
       "6  0.852  0.904  0.962  0.626  0.540  0.990  1.000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_benign_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.962</td>\n",
       "      <td>0.446</td>\n",
       "      <td>0.338</td>\n",
       "      <td>0.952</td>\n",
       "      <td>0.944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.538</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.726</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.796</td>\n",
       "      <td>0.834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.900</td>\n",
       "      <td>0.922</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.398</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.974</td>\n",
       "      <td>0.976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.706</td>\n",
       "      <td>0.696</td>\n",
       "      <td>0.746</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.790</td>\n",
       "      <td>0.502</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.558</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.838</td>\n",
       "      <td>0.940</td>\n",
       "      <td>0.980</td>\n",
       "      <td>0.332</td>\n",
       "      <td>0.164</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.780</td>\n",
       "      <td>0.944</td>\n",
       "      <td>0.970</td>\n",
       "      <td>0.312</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.992</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1      2      3      4      5      6\n",
       "0  1.000  0.816  0.962  0.446  0.338  0.952  0.944\n",
       "1  0.538  1.000  0.726  0.202  0.104  0.796  0.834\n",
       "2  0.900  0.922  1.000  0.398  0.170  0.974  0.976\n",
       "3  0.706  0.696  0.746  1.000  0.400  0.732  0.724\n",
       "4  0.790  0.502  0.714  0.558  1.000  0.676  0.654\n",
       "5  0.838  0.940  0.980  0.332  0.164  1.000  0.996\n",
       "6  0.780  0.944  0.970  0.312  0.156  0.992  1.000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_adv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.879195</td>\n",
       "      <td>0.709172</td>\n",
       "      <td>0.854586</td>\n",
       "      <td>0.304251</td>\n",
       "      <td>0.205817</td>\n",
       "      <td>0.843400</td>\n",
       "      <td>0.834452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.417978</td>\n",
       "      <td>0.876405</td>\n",
       "      <td>0.593258</td>\n",
       "      <td>0.096629</td>\n",
       "      <td>0.026966</td>\n",
       "      <td>0.662921</td>\n",
       "      <td>0.703371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.820346</td>\n",
       "      <td>0.841991</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.311688</td>\n",
       "      <td>0.088745</td>\n",
       "      <td>0.913420</td>\n",
       "      <td>0.911255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.616071</td>\n",
       "      <td>0.629464</td>\n",
       "      <td>0.676339</td>\n",
       "      <td>0.747768</td>\n",
       "      <td>0.220982</td>\n",
       "      <td>0.669643</td>\n",
       "      <td>0.662946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.703057</td>\n",
       "      <td>0.368996</td>\n",
       "      <td>0.600437</td>\n",
       "      <td>0.353712</td>\n",
       "      <td>0.762009</td>\n",
       "      <td>0.561135</td>\n",
       "      <td>0.539301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.716854</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.844944</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.056180</td>\n",
       "      <td>0.858427</td>\n",
       "      <td>0.858427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.677778</td>\n",
       "      <td>0.817778</td>\n",
       "      <td>0.844444</td>\n",
       "      <td>0.202222</td>\n",
       "      <td>0.057778</td>\n",
       "      <td>0.862222</td>\n",
       "      <td>0.866667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6\n",
       "0  0.879195  0.709172  0.854586  0.304251  0.205817  0.843400  0.834452\n",
       "1  0.417978  0.876405  0.593258  0.096629  0.026966  0.662921  0.703371\n",
       "2  0.820346  0.841991  0.909091  0.311688  0.088745  0.913420  0.911255\n",
       "3  0.616071  0.629464  0.676339  0.747768  0.220982  0.669643  0.662946\n",
       "4  0.703057  0.368996  0.600437  0.353712  0.762009  0.561135  0.539301\n",
       "5  0.716854  0.820225  0.844944  0.200000  0.056180  0.858427  0.858427\n",
       "6  0.677778  0.817778  0.844444  0.202222  0.057778  0.862222  0.866667"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_adv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grad_align_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orig_acc_mean 0.7151428923314932\n",
      "Sim Benign Mean 0.7690204400189069\n",
      "Target ADV Mean 0.6040968042703307\n"
     ]
    }
   ],
   "source": [
    "# Average all the information together and present\n",
    "orig_acc_mean = np.mean(orig_acc)\n",
    "sim_benign_mean = np.mean(sim_benign)\n",
    "sim_adv_mean = np.mean(sim_adv_df)\n",
    "target_adv_mean = np.mean(target_adv)\n",
    "# grad_align_mean = np.mean((grad_align.sum(1)-0)/(grad_align.shape[1]-0))\n",
    "\n",
    "print(\"orig_acc_mean\", orig_acc_mean)\n",
    "print(\"Sim Benign Mean\", sim_benign_mean)\n",
    "# print(\"Sim ADV Mean\", sim_adv_mean)\n",
    "print(\"Target ADV Mean\", target_adv_mean)\n",
    "# print(\"Grad Align Mean\", grad_align_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(14.8801, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(17.0992, device='cuda:0', grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "# Calculate average distance norm across examples\n",
    "delta = t1.x_adv - t1.x_orig\n",
    "dnorm = delta.view(delta.shape[0], -1).norm(float(2), dim=1)\n",
    "print(torch.mean(dnorm))\n",
    "print(torch.max(dnorm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8203"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# IFSGM\n",
    "4.5347 # mean\n",
    "4.8902 # Max\n",
    "0.8203 # Mean transfer rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8594"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PGD\n",
    "4.4978 # mean perturbation\n",
    "4.5000 # Max perturbation\n",
    "0.8594 # Mean transfer rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print image of L2 norm of different values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FedEM_env",
   "language": "python",
   "name": "fedem_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
